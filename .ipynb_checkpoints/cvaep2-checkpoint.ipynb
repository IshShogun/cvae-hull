{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a96622b7-9564-4921-a263-ba72644bbb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###CNN and MLP primitive\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "##The encoder in the paper takes x in R^(TxHxW) and y in R^(TxE) and maps them to R^(TxL) the dimensionality of the context encoder\n",
    "##and encoder is set to 5. So this cnn needs to output (32x5) so each (surface in R^(5x5) -> (z in R^5)\n",
    "\n",
    "##we enhance the dimensionality of the iv surface first by upgrading the number of channels. The reasoning behind this is similar to why \n",
    "##we do this in transformer architecture. A larger dimensional space will be able to capture more nuanced information and represent it in number form\n",
    "##then we compress this to something digestable\n",
    "class CNN(nn.Module):\n",
    "    #input_size and output_size represent the number of channels in the input and output data\n",
    "    #channels is the number of dimensions a single data point will have ie RGB = 3 channelss\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_size, output_size, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(output_size, output_size, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(output_size, output_size, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc = nn.Linear(output_size * 5 * 5, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, H, W = x.shape\n",
    "        x = x.reshape(batch_size, 1, H, W)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        #print(f\"x shape before resize and convultion passthrough is {x.shape}\")\n",
    "        #x = x.reshape(batch_size, 1, 5)\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.fc(x)\n",
    "        #print(f\"after passthrough into convultion layers and fully connected layer ther shape of x is {x.shape}\")\n",
    "        return x\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, y):\n",
    "        x = F.relu(self.fc1(y))\n",
    "        x = self.fc2(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "377a416f-980c-4024-bb50-115fb221343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###CNN For decoder \n",
    "\n",
    "#due to difference in dimensionality - What happened st i needed to make this. z, zeta make different shape so needed redfinition\n",
    "##plus it will define a new coniditional probability distribtution\n",
    "\n",
    "##had to make another cnn for decoder due difference in dimensionality\n",
    "\n",
    "##in here the output size should be the number of days in the future?\n",
    "\n",
    "##for now output_size = 1 so we predict 1 day into the future?\n",
    "class TCNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_surfaces):\n",
    "        super(TCNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 5 * 5 * num_surfaces)\n",
    "        self.output_size = output_size\n",
    "        self.num_surfaces = num_surfaces\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = x.view(-1, self.num_surfaces, 5, 5)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3016d2ec-e952-4aa8-ad75-2cf4b43b5fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###ENCODER DECODER CONTEXTENCODER\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, latent_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.cnn = CNN(input_size, 5)\n",
    "        self.mlp = nn.Identity()\n",
    "        self.lstm = nn.LSTM(5 + 3, hidden_size, num_layers=2, batch_first=True, dropout=0.2)\n",
    "        self.linear_mu = nn.Linear(hidden_size, latent_size)\n",
    "        self.linear_sigma = nn.Linear(hidden_size, latent_size)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x_encoded = self.cnn(x)\n",
    "        y_encoded = self.mlp(y)\n",
    "        y_encoded = torch.squeeze(y_encoded, dim=1)\n",
    "        #print(f\"x_encoded shape is {x_encoded.shape}  y_encoded shape is {y_encoded.shape}\")\n",
    "        encoded = torch.cat((x_encoded, y_encoded), dim=-1)\n",
    "        #print(f\"concatenated vector is of size {encoded.shape}\")\n",
    "        _, (hidden, _) = self.lstm(encoded)\n",
    "        #print(\"hidden state created\")\n",
    "        hidden = hidden[-1]  # Take the last hidden state\n",
    "        mu = self.linear_mu(hidden)\n",
    "        log_var = self.linear_sigma(hidden)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        #print(\"encoding successful\")\n",
    "        return z, mu, log_var\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "class ContextEncoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, context_size):\n",
    "        super(ContextEncoder, self).__init__()\n",
    "        self.cnn = CNN(input_size, 5)\n",
    "        self.mlp = nn.Identity()\n",
    "        self.lstm = nn.LSTM(5 + 3, hidden_size, num_layers=2, batch_first=True, dropout=0.2)\n",
    "        self.linear = nn.Linear(hidden_size, context_size)\n",
    "\n",
    "    def forward(self, x_c, y_c):\n",
    "        x_encoded = self.cnn(x_c)\n",
    "        y_encoded = self.mlp(y_c)\n",
    "        y_encoded = torch.squeeze(y_encoded, dim=1)\n",
    "        #print(f\"x_encoded size = {x_encoded.shape} ||y_encoded size = {y_encoded.shape}\")\n",
    "        encoded = torch.cat((x_encoded, y_encoded), dim=-1)\n",
    "        _, (hidden, _) = self.lstm(encoded)\n",
    "        hidden = hidden[-1]  # Take the last hidden state\n",
    "        zeta = self.linear(hidden)\n",
    "        #print(\"context encoding successful\")\n",
    "        return zeta\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_size, hidden_size, output_size, num_surfaces):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(latent_size + 5, hidden_size, num_layers=2, batch_first=True, dropout=0.2) #latent\n",
    "        self.tcnn = TCNN(hidden_size, output_size, num_surfaces)\n",
    "        self.mlp = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, z, zeta):\n",
    "        # Reshape z and zeta to have shape (1, 5)\n",
    "        z = z.view(1, -1)\n",
    "        zeta = zeta.view(1, -1)\n",
    "        # Concatenate z and zeta along the second dimension to get shape (1, 10)\n",
    "        z_concat = torch.cat((z, zeta), dim=1)\n",
    "        \n",
    "        #print(f\"z_concat is of size {z_concat.shape}\")\n",
    "        hidden, _ = self.lstm(z_concat)\n",
    "        #print('i am here')\n",
    "        #print(f\"hidden state published, hidden state shape {hidden.shape}\")\n",
    "        x_n = self.tcnn(hidden) \n",
    "        #print('i am here')\n",
    "        r_n = self.mlp(hidden)\n",
    "        #print(\"decoding successful\")\n",
    "        return torch.squeeze(x_n, dim=0), torch.squeeze(r_n, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e680583a-05fe-4c3b-bfa2-57a888c03fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moneyness levels and time to maturity (in days ##based of paper single skew and slope for surface\n",
    "moneyness_levels = [0.7, 0.85, 1, 1.15, 1.3]\n",
    "ttm_levels = [1, 3, 6, 12, 24] #days\n",
    "\n",
    "def calculate_skew_slope(iv_row):\n",
    "    # Select IV values for the specific TTM and moneyness levels\n",
    "    iv_12d_085 = iv_row.get((12, 0.85), 0)  # IV for 1 year TTM and moneyness=0.85\n",
    "    iv_12d_100 = iv_row.get((12, 1.00), 0)  # IV for 1 year TTM and moneyness=1.00\n",
    "    iv_12d_115 = iv_row.get((12, 1.15), 0)  # IV for 1 year TTM and moneyness=1.15\n",
    "\n",
    "    # Calculate skew\n",
    "    skew = (iv_12d_085 + iv_12d_115) / 2 - iv_12d_100 if iv_12d_100 else 0  # Avoid division by zero\n",
    "\n",
    "    # Select IV values for slope calculation\n",
    "    iv_3d_100 = iv_row.get((3, 1.00), 0)  # IV for 3 months TTM and moneyness=1.00\n",
    "    iv_24d_100 = iv_row.get((24, 1.00), 0)  # IV for 2 years TTM and moneyness=1.00\n",
    "\n",
    "    # Calculate slope\n",
    "    slope = iv_24d_100 - iv_3d_100\n",
    "\n",
    "    return skew, slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16fe4a5a-20e5-4168-bd9c-03ab231b460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###CVAE\n",
    "\n",
    "class CVAE(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, latent_size, context_size, output_size, num_surfaces):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.encoder = Encoder(input_size, hidden_size, latent_size)\n",
    "        self.context_encoder = ContextEncoder(input_size, hidden_size, context_size)\n",
    "        self.decoder = Decoder(latent_size, hidden_size, output_size, num_surfaces)\n",
    "        self.latent_size = latent_size\n",
    "        self.context_size = context_size\n",
    "\n",
    "    def forward(self, x, y, x_c, y_c):\n",
    "        #print('1')\n",
    "        z, mu, log_var = self.encoder(x, y) ##we have sampled z from distribution here\n",
    "        #print(f\"The shape of latent representation z is {z.shape}\")\n",
    "        #print('2')\n",
    "        zeta = self.context_encoder(x_c, y_c) ##we have sampled zeta from distribution here\n",
    "        #print(f\"the shape of zeta (encoded context) is {zeta.shape}\")\n",
    "        x_n, r_n = self.decoder(z, zeta)\n",
    "        return x_n, r_n, mu, log_var\n",
    "\n",
    "    \n",
    "    def generate(self, x_c, y_c, ttm):\n",
    "        x_hat = []\n",
    "        r_hat = []\n",
    "    \n",
    "        for i in range(0, ttm):\n",
    "            # reasing z and context\n",
    "            z = torch.tensor(np.array([np.random.normal(loc=0, scale=1, size=5)]), dtype=torch.float32)\n",
    "            zeta = self.context_encoder(x_c, y_c)\n",
    "            x_n, r_n = self.decoder(z, zeta)\n",
    "            x_hat.append(x_n)\n",
    "            r_hat.append(r_n)\n",
    "    \n",
    "            # Update x_c by removing the first value and appending x_n\n",
    "            x_c = torch.cat((x_c[1:], x_n[0].unsqueeze(0)))\n",
    "    \n",
    "            # Convert x_n (generated IV surfaces) to a dictionary format\n",
    "            iv_row = {(ttm, moneyness): x_n[0][i, j] for i, moneyness in enumerate(moneyness_levels) for j, ttm in enumerate(ttm_levels)}\n",
    "    \n",
    "            # Calculate skew and slope using the calculate_skew_slope function\n",
    "            skew, slope = calculate_skew_slope(iv_row)\n",
    "           # print(skew)\n",
    "            #print(slope)\n",
    "    \n",
    "            # Create y_n by combining r_n (predicted log returns), skew, and slope\n",
    "            y_n = torch.cat((r_n, torch.tensor([skew, slope])))\n",
    "\n",
    "            y_n = y_n.view(1, -1)\n",
    "            #print(y_c)\n",
    "            #print(y_n)\n",
    "            # Update y_c by removing the first value and appending y_n\n",
    "            y_c = torch.cat((y_c[1:], y_n.unsqueeze(0)))\n",
    "    \n",
    "        return x_hat, r_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d3be940-4695-424d-8c99-f1964625f3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sl/_44jn7jx03b17y35qvlp17sr0000gn/T/ipykernel_28197/3904911613.py:14: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  X = df.drop(['Log Return', 'Skew', 'Slope'], axis=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the DataFrame from the provided CSV file\n",
    "file_path = 'combined_iv_data.csv'\n",
    "df = pd.read_csv(file_path, header=[0, 1], index_col=0)\n",
    "\n",
    "# Extract extra features\n",
    "Y = df[['Log Return', 'Skew', 'Slope']]\n",
    "\n",
    "# Extract IV surface data\n",
    "X = df.drop(['Log Return', 'Skew', 'Slope'], axis=1)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "Y_scaled = scaler.fit_transform(Y)\n",
    "\n",
    "# Split data into training and temporary set\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, Y_scaled, test_size=2000, random_state=42)\n",
    "\n",
    "# Split the temporary set into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a68456d-e530-49b0-847a-d1ea1f5f2fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_random_day(n):\n",
    "    \"\"\"\n",
    "    Generates a random number between 1 and n\n",
    "    \"\"\"\n",
    "    # Generate a random number between 1 and n\n",
    "    random_number = random.randint(1, n - 1)\n",
    "    return random_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "503837b1-b9d2-4aba-b37f-3a91318a0a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "###PREPARE DATA\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils import mkldnn as mkldnn_utils\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 25\n",
    "hidden_size = 100\n",
    "latent_size = 5\n",
    "context_size = 5\n",
    "input_size = 1\n",
    "output_size = 5\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 500\n",
    "batch_size = 32\n",
    "alpha = 1.0\n",
    "beta = 1e-5\n",
    "\n",
    "\n",
    "# Reshape the input data to the desired 5-dimensional shape\n",
    "batch_size_train = X_train.shape[0]\n",
    "batch_size_val = X_val.shape[0]\n",
    "batch_size_test = X_test.shape[0]\n",
    "sequence_length = 1  # \n",
    "num_surfaces = 1  # the number of surfaces to generate\n",
    "\n",
    "\n",
    "H = 5  # Height of the IV surface grid\n",
    "W = 5  # Width of the IV surface grid\n",
    "\n",
    "#print(X_train.shape)\n",
    "X_train_reshaped = X_train.reshape(batch_size_train,  H, W)\n",
    "X_val_reshaped = X_val.reshape(batch_size_val, H, W)\n",
    "X_test_reshaped = X_test.reshape(batch_size_test, H, W)\n",
    "#print(X_train_reshaped.shape)\n",
    "extra_features_size = 3\n",
    "\n",
    "y_train_reshaped = y_train.reshape(y_train.shape[0], 1, extra_features_size)\n",
    "y_val_reshaped = y_val.reshape(y_val.shape[0], 1, extra_features_size)\n",
    "y_test_reshaped = y_test.reshape(y_test.shape[0], 1, extra_features_size)\n",
    "\n",
    "train_data = TensorDataset(torch.Tensor(X_train_reshaped), torch.Tensor(y_train_reshaped))\n",
    "val_data = TensorDataset(torch.Tensor(X_val_reshaped), torch.Tensor(y_val_reshaped))\n",
    "test_data = TensorDataset(torch.Tensor(X_test_reshaped), torch.Tensor(y_test_reshaped))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Create the model\n",
    "model = CVAE(input_size, hidden_size, latent_size, context_size, input_size, num_surfaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cfc4fe-13dd-4d85-b490-ab4eb4620f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sl/_44jn7jx03b17y35qvlp17sr0000gn/T/ipykernel_25241/3936122436.py:10: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  recon_loss_r = F.mse_loss(r_n_recon, r_n, reduction='mean')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_n_recon: tensor([[[ 0.0401,  0.0353, -0.0685, -0.0107,  0.0291],\n",
      "         [-0.0173,  0.0663,  0.0305,  0.0289, -0.0093],\n",
      "         [ 0.0492, -0.0367, -0.0147,  0.0218, -0.0488],\n",
      "         [ 0.0534, -0.0179, -0.0104,  0.0706,  0.0266],\n",
      "         [ 0.0065, -0.0084,  0.0286, -0.0251, -0.0298]]])\n",
      "x_n_recon: tensor([[[ 0.0413,  0.0363, -0.0690, -0.0094,  0.0300],\n",
      "         [-0.0169,  0.0671,  0.0302,  0.0296, -0.0091],\n",
      "         [ 0.0501, -0.0366, -0.0132,  0.0221, -0.0490],\n",
      "         [ 0.0544, -0.0171, -0.0091,  0.0709,  0.0274],\n",
      "         [ 0.0074, -0.0074,  0.0292, -0.0247, -0.0307]]])\n",
      "x_n_recon: tensor([[[ 0.0418,  0.0365, -0.0690, -0.0094,  0.0307],\n",
      "         [-0.0158,  0.0674,  0.0302,  0.0303, -0.0083],\n",
      "         [ 0.0507, -0.0360, -0.0127,  0.0219, -0.0490],\n",
      "         [ 0.0558, -0.0172, -0.0080,  0.0721,  0.0280],\n",
      "         [ 0.0079, -0.0061,  0.0297, -0.0249, -0.0316]]])\n",
      "x_n_recon: tensor([[[ 0.0388,  0.0338, -0.0678, -0.0125,  0.0281],\n",
      "         [-0.0180,  0.0649,  0.0315,  0.0267, -0.0098],\n",
      "         [ 0.0479, -0.0376, -0.0169,  0.0206, -0.0485],\n",
      "         [ 0.0509, -0.0185, -0.0120,  0.0697,  0.0246],\n",
      "         [ 0.0040, -0.0104,  0.0271, -0.0253, -0.0280]]])\n",
      "x_n_recon: tensor([[[ 0.0398,  0.0350, -0.0685, -0.0110,  0.0288],\n",
      "         [-0.0176,  0.0661,  0.0307,  0.0284, -0.0096],\n",
      "         [ 0.0488, -0.0371, -0.0152,  0.0215, -0.0487],\n",
      "         [ 0.0528, -0.0178, -0.0108,  0.0701,  0.0260],\n",
      "         [ 0.0060, -0.0091,  0.0282, -0.0250, -0.0293]]])\n",
      "x_n_recon: tensor([[[ 0.0397,  0.0347, -0.0683, -0.0113,  0.0287],\n",
      "         [-0.0176,  0.0659,  0.0309,  0.0281, -0.0097],\n",
      "         [ 0.0487, -0.0371, -0.0155,  0.0214, -0.0487],\n",
      "         [ 0.0525, -0.0180, -0.0111,  0.0701,  0.0258],\n",
      "         [ 0.0057, -0.0093,  0.0280, -0.0250, -0.0291]]])\n",
      "x_n_recon: tensor([[[ 0.0408,  0.0360, -0.0688, -0.0101,  0.0297],\n",
      "         [-0.0169,  0.0669,  0.0303,  0.0296, -0.0091],\n",
      "         [ 0.0498, -0.0365, -0.0138,  0.0220, -0.0491],\n",
      "         [ 0.0544, -0.0174, -0.0095,  0.0710,  0.0273],\n",
      "         [ 0.0072, -0.0075,  0.0291, -0.0250, -0.0306]]])\n",
      "x_n_recon: tensor([[[ 0.0400,  0.0351, -0.0685, -0.0108,  0.0290],\n",
      "         [-0.0174,  0.0662,  0.0306,  0.0287, -0.0095],\n",
      "         [ 0.0490, -0.0368, -0.0149,  0.0217, -0.0488],\n",
      "         [ 0.0531, -0.0179, -0.0106,  0.0704,  0.0263],\n",
      "         [ 0.0063, -0.0087,  0.0284, -0.0251, -0.0297]]])\n",
      "x_n_recon: tensor([[[ 0.0427,  0.0369, -0.0692, -0.0083,  0.0314],\n",
      "         [-0.0153,  0.0676,  0.0300,  0.0307, -0.0080],\n",
      "         [ 0.0513, -0.0358, -0.0116,  0.0220, -0.0490],\n",
      "         [ 0.0563, -0.0170, -0.0071,  0.0724,  0.0284],\n",
      "         [ 0.0083, -0.0054,  0.0301, -0.0247, -0.0323]]])\n",
      "x_n_recon: tensor([[[ 0.0420,  0.0366, -0.0689, -0.0087,  0.0307],\n",
      "         [-0.0157,  0.0673,  0.0301,  0.0303, -0.0085],\n",
      "         [ 0.0508, -0.0359, -0.0123,  0.0221, -0.0490],\n",
      "         [ 0.0556, -0.0172, -0.0080,  0.0719,  0.0280],\n",
      "         [ 0.0080, -0.0061,  0.0299, -0.0248, -0.0319]]])\n",
      "x_n_recon: tensor([[[ 0.0399,  0.0350, -0.0684, -0.0111,  0.0288],\n",
      "         [-0.0175,  0.0660,  0.0307,  0.0284, -0.0095],\n",
      "         [ 0.0489, -0.0370, -0.0151,  0.0216, -0.0487],\n",
      "         [ 0.0529, -0.0180, -0.0108,  0.0704,  0.0261],\n",
      "         [ 0.0060, -0.0088,  0.0283, -0.0251, -0.0294]]])\n",
      "x_n_recon: tensor([[[ 0.0385,  0.0335, -0.0676, -0.0128,  0.0280],\n",
      "         [-0.0181,  0.0646,  0.0317,  0.0265, -0.0098],\n",
      "         [ 0.0477, -0.0376, -0.0174,  0.0204, -0.0486],\n",
      "         [ 0.0505, -0.0187, -0.0123,  0.0693,  0.0243],\n",
      "         [ 0.0036, -0.0109,  0.0269, -0.0253, -0.0278]]])\n",
      "x_n_recon: tensor([[[ 0.0409,  0.0362, -0.0689, -0.0100,  0.0297],\n",
      "         [-0.0168,  0.0669,  0.0303,  0.0296, -0.0090],\n",
      "         [ 0.0499, -0.0365, -0.0136,  0.0221, -0.0491],\n",
      "         [ 0.0545, -0.0174, -0.0094,  0.0711,  0.0274],\n",
      "         [ 0.0072, -0.0074,  0.0292, -0.0249, -0.0307]]])\n",
      "x_n_recon: tensor([[[ 0.0400,  0.0354, -0.0684, -0.0108,  0.0289],\n",
      "         [-0.0175,  0.0661,  0.0306,  0.0285, -0.0096],\n",
      "         [ 0.0490, -0.0370, -0.0148,  0.0219, -0.0487],\n",
      "         [ 0.0530, -0.0179, -0.0108,  0.0703,  0.0263],\n",
      "         [ 0.0061, -0.0087,  0.0285, -0.0251, -0.0296]]])\n",
      "x_n_recon: tensor([[[ 0.0400,  0.0351, -0.0685, -0.0109,  0.0291],\n",
      "         [-0.0171,  0.0663,  0.0306,  0.0291, -0.0092],\n",
      "         [ 0.0492, -0.0365, -0.0148,  0.0216, -0.0489],\n",
      "         [ 0.0536, -0.0180, -0.0102,  0.0708,  0.0266],\n",
      "         [ 0.0065, -0.0083,  0.0286, -0.0251, -0.0299]]])\n",
      "x_n_recon: tensor([[[ 0.0431,  0.0371, -0.0693, -0.0075,  0.0316],\n",
      "         [-0.0153,  0.0679,  0.0300,  0.0310, -0.0080],\n",
      "         [ 0.0516, -0.0356, -0.0112,  0.0219, -0.0491],\n",
      "         [ 0.0563, -0.0166, -0.0067,  0.0722,  0.0283],\n",
      "         [ 0.0084, -0.0055,  0.0302, -0.0243, -0.0324]]])\n",
      "x_n_recon: tensor([[[ 0.0413,  0.0363, -0.0690, -0.0095,  0.0301],\n",
      "         [-0.0168,  0.0672,  0.0302,  0.0297, -0.0089],\n",
      "         [ 0.0502, -0.0365, -0.0132,  0.0219, -0.0490],\n",
      "         [ 0.0546, -0.0170, -0.0089,  0.0711,  0.0275],\n",
      "         [ 0.0074, -0.0072,  0.0292, -0.0247, -0.0307]]])\n",
      "x_n_recon: tensor([[[ 0.0390,  0.0339, -0.0681, -0.0120,  0.0283],\n",
      "         [-0.0182,  0.0653,  0.0313,  0.0272, -0.0100],\n",
      "         [ 0.0481, -0.0376, -0.0165,  0.0207, -0.0485],\n",
      "         [ 0.0512, -0.0182, -0.0118,  0.0692,  0.0248],\n",
      "         [ 0.0045, -0.0105,  0.0274, -0.0249, -0.0281]]])\n",
      "x_n_recon: tensor([[[ 0.0410,  0.0363, -0.0689, -0.0100,  0.0298],\n",
      "         [-0.0166,  0.0670,  0.0303,  0.0296, -0.0089],\n",
      "         [ 0.0500, -0.0365, -0.0134,  0.0220, -0.0489],\n",
      "         [ 0.0547, -0.0174, -0.0092,  0.0713,  0.0275],\n",
      "         [ 0.0073, -0.0070,  0.0292, -0.0250, -0.0307]]])\n",
      "x_n_recon: tensor([[[ 0.0386,  0.0337, -0.0676, -0.0124,  0.0280],\n",
      "         [-0.0182,  0.0647,  0.0316,  0.0267, -0.0099],\n",
      "         [ 0.0476, -0.0376, -0.0172,  0.0209, -0.0488],\n",
      "         [ 0.0506, -0.0186, -0.0125,  0.0691,  0.0245],\n",
      "         [ 0.0038, -0.0108,  0.0273, -0.0252, -0.0281]]])\n",
      "x_n_recon: tensor([[[ 0.0377,  0.0325, -0.0670, -0.0135,  0.0276],\n",
      "         [-0.0187,  0.0636,  0.0323,  0.0253, -0.0102],\n",
      "         [ 0.0467, -0.0380, -0.0187,  0.0199, -0.0486],\n",
      "         [ 0.0488, -0.0191, -0.0134,  0.0682,  0.0232],\n",
      "         [ 0.0022, -0.0124,  0.0262, -0.0252, -0.0272]]])\n",
      "x_n_recon: tensor([[[ 0.0399,  0.0346, -0.0683, -0.0114,  0.0292],\n",
      "         [-0.0168,  0.0661,  0.0307,  0.0290, -0.0088],\n",
      "         [ 0.0493, -0.0363, -0.0151,  0.0214, -0.0489],\n",
      "         [ 0.0536, -0.0183, -0.0101,  0.0713,  0.0264],\n",
      "         [ 0.0065, -0.0082,  0.0284, -0.0253, -0.0298]]])\n",
      "x_n_recon: tensor([[[ 0.0421,  0.0366, -0.0691, -0.0086,  0.0307],\n",
      "         [-0.0161,  0.0674,  0.0300,  0.0301, -0.0086],\n",
      "         [ 0.0507, -0.0362, -0.0122,  0.0221, -0.0489],\n",
      "         [ 0.0552, -0.0169, -0.0080,  0.0715,  0.0279],\n",
      "         [ 0.0079, -0.0065,  0.0297, -0.0246, -0.0315]]])\n",
      "x_n_recon: tensor([[[ 0.0412,  0.0364, -0.0689, -0.0097,  0.0300],\n",
      "         [-0.0166,  0.0670,  0.0303,  0.0299, -0.0088],\n",
      "         [ 0.0502, -0.0364, -0.0132,  0.0221, -0.0491],\n",
      "         [ 0.0549, -0.0173, -0.0090,  0.0713,  0.0276],\n",
      "         [ 0.0075, -0.0070,  0.0294, -0.0249, -0.0310]]])\n",
      "x_n_recon: tensor([[[ 0.0382,  0.0330, -0.0674, -0.0130,  0.0277],\n",
      "         [-0.0186,  0.0642,  0.0319,  0.0258, -0.0103],\n",
      "         [ 0.0472, -0.0380, -0.0180,  0.0202, -0.0485],\n",
      "         [ 0.0495, -0.0187, -0.0129,  0.0685,  0.0237],\n",
      "         [ 0.0029, -0.0118,  0.0265, -0.0251, -0.0273]]])\n",
      "x_n_recon: tensor([[[ 0.0386,  0.0336, -0.0676, -0.0124,  0.0280],\n",
      "         [-0.0184,  0.0646,  0.0316,  0.0264, -0.0101],\n",
      "         [ 0.0475, -0.0378, -0.0173,  0.0207, -0.0486],\n",
      "         [ 0.0503, -0.0185, -0.0126,  0.0688,  0.0243],\n",
      "         [ 0.0037, -0.0111,  0.0271, -0.0251, -0.0279]]])\n",
      "x_n_recon: tensor([[[ 0.0404,  0.0358, -0.0687, -0.0105,  0.0293],\n",
      "         [-0.0171,  0.0666,  0.0304,  0.0292, -0.0093],\n",
      "         [ 0.0495, -0.0367, -0.0142,  0.0219, -0.0489],\n",
      "         [ 0.0539, -0.0176, -0.0100,  0.0708,  0.0269],\n",
      "         [ 0.0068, -0.0079,  0.0289, -0.0251, -0.0302]]])\n",
      "x_n_recon: tensor([[[ 0.0393,  0.0346, -0.0683, -0.0116,  0.0284],\n",
      "         [-0.0180,  0.0656,  0.0310,  0.0279, -0.0097],\n",
      "         [ 0.0485, -0.0374, -0.0158,  0.0213, -0.0487],\n",
      "         [ 0.0520, -0.0180, -0.0115,  0.0698,  0.0256],\n",
      "         [ 0.0052, -0.0096,  0.0279, -0.0251, -0.0286]]])\n",
      "x_n_recon: tensor([[[ 0.0399,  0.0348, -0.0683, -0.0111,  0.0290],\n",
      "         [-0.0172,  0.0661,  0.0307,  0.0284, -0.0095],\n",
      "         [ 0.0490, -0.0368, -0.0151,  0.0214, -0.0486],\n",
      "         [ 0.0530, -0.0181, -0.0105,  0.0706,  0.0261],\n",
      "         [ 0.0061, -0.0088,  0.0282, -0.0251, -0.0295]]])\n",
      "x_n_recon: tensor([[[ 0.0420,  0.0365, -0.0691, -0.0088,  0.0305],\n",
      "         [-0.0162,  0.0674,  0.0300,  0.0300, -0.0088],\n",
      "         [ 0.0505, -0.0363, -0.0125,  0.0219, -0.0489],\n",
      "         [ 0.0551, -0.0169, -0.0082,  0.0714,  0.0278],\n",
      "         [ 0.0078, -0.0066,  0.0295, -0.0247, -0.0312]]])\n",
      "x_n_recon: tensor([[[ 0.0414,  0.0364, -0.0689, -0.0095,  0.0303],\n",
      "         [-0.0164,  0.0672,  0.0302,  0.0301, -0.0086],\n",
      "         [ 0.0503, -0.0362, -0.0130,  0.0221, -0.0491],\n",
      "         [ 0.0551, -0.0173, -0.0086,  0.0715,  0.0278],\n",
      "         [ 0.0076, -0.0068,  0.0295, -0.0248, -0.0313]]])\n",
      "x_n_recon: tensor([[[ 0.0360,  0.0297, -0.0654, -0.0156,  0.0264],\n",
      "         [-0.0195,  0.0609,  0.0338,  0.0214, -0.0114],\n",
      "         [ 0.0444, -0.0395, -0.0221,  0.0182, -0.0484],\n",
      "         [ 0.0444, -0.0202, -0.0164,  0.0667,  0.0205],\n",
      "         [-0.0017, -0.0156,  0.0230, -0.0261, -0.0249]]])\n",
      "Epoch [1/500], Train Loss: 1.0446, Val Loss: 1.0237\n",
      "x_n_recon: tensor([[[ 0.0399,  0.0146, -0.0433, -0.0343,  0.0202],\n",
      "         [-0.0271,  0.0477,  0.0321, -0.0052, -0.0206],\n",
      "         [ 0.0460, -0.0257, -0.0345,  0.0247, -0.0622],\n",
      "         [ 0.0279, -0.0260, -0.0080,  0.0479,  0.0271],\n",
      "         [-0.0034, -0.0116, -0.0007, -0.0395, -0.0318]]])\n",
      "x_n_recon: tensor([[[ 0.0406,  0.0144, -0.0431, -0.0340,  0.0208],\n",
      "         [-0.0277,  0.0478,  0.0337, -0.0057, -0.0205],\n",
      "         [ 0.0461, -0.0257, -0.0347,  0.0241, -0.0627],\n",
      "         [ 0.0274, -0.0261, -0.0074,  0.0480,  0.0280],\n",
      "         [-0.0040, -0.0122, -0.0013, -0.0381, -0.0305]]])\n",
      "x_n_recon: tensor([[[ 0.0396,  0.0150, -0.0434, -0.0335,  0.0195],\n",
      "         [-0.0275,  0.0483,  0.0310, -0.0051, -0.0213],\n",
      "         [ 0.0459, -0.0255, -0.0339,  0.0250, -0.0621],\n",
      "         [ 0.0282, -0.0262, -0.0086,  0.0470,  0.0265],\n",
      "         [-0.0025, -0.0116, -0.0011, -0.0404, -0.0326]]])\n",
      "x_n_recon: tensor([[[ 0.0406,  0.0140, -0.0432, -0.0339,  0.0206],\n",
      "         [-0.0273,  0.0478,  0.0331, -0.0059, -0.0204],\n",
      "         [ 0.0460, -0.0259, -0.0345,  0.0239, -0.0626],\n",
      "         [ 0.0270, -0.0257, -0.0077,  0.0480,  0.0274],\n",
      "         [-0.0042, -0.0116, -0.0015, -0.0386, -0.0302]]])\n",
      "x_n_recon: tensor([[[ 0.0411,  0.0140, -0.0431, -0.0342,  0.0208],\n",
      "         [-0.0276,  0.0480,  0.0340, -0.0060, -0.0206],\n",
      "         [ 0.0463, -0.0258, -0.0347,  0.0236, -0.0626],\n",
      "         [ 0.0274, -0.0261, -0.0070,  0.0482,  0.0279],\n",
      "         [-0.0039, -0.0124, -0.0015, -0.0376, -0.0298]]])\n",
      "x_n_recon: tensor([[[ 0.0432,  0.0114, -0.0424, -0.0338,  0.0217],\n",
      "         [-0.0280,  0.0475,  0.0386, -0.0084, -0.0195],\n",
      "         [ 0.0467, -0.0265, -0.0363,  0.0212, -0.0653],\n",
      "         [ 0.0240, -0.0247, -0.0065,  0.0487,  0.0287],\n",
      "         [-0.0069, -0.0131, -0.0048, -0.0354, -0.0250]]])\n",
      "x_n_recon: tensor([[[ 0.0398,  0.0150, -0.0431, -0.0338,  0.0199],\n",
      "         [-0.0278,  0.0482,  0.0322, -0.0053, -0.0210],\n",
      "         [ 0.0460, -0.0254, -0.0344,  0.0247, -0.0624],\n",
      "         [ 0.0280, -0.0263, -0.0081,  0.0471,  0.0271],\n",
      "         [-0.0031, -0.0121, -0.0012, -0.0395, -0.0319]]])\n",
      "x_n_recon: tensor([[[ 0.0392,  0.0151, -0.0435, -0.0327,  0.0191],\n",
      "         [-0.0277,  0.0480,  0.0300, -0.0047, -0.0220],\n",
      "         [ 0.0461, -0.0255, -0.0333,  0.0257, -0.0620],\n",
      "         [ 0.0284, -0.0263, -0.0093,  0.0463,  0.0261],\n",
      "         [-0.0019, -0.0116, -0.0006, -0.0407, -0.0337]]])\n",
      "x_n_recon: tensor([[[ 0.0392,  0.0153, -0.0434, -0.0326,  0.0191],\n",
      "         [-0.0278,  0.0479,  0.0301, -0.0047, -0.0219],\n",
      "         [ 0.0460, -0.0255, -0.0333,  0.0258, -0.0621],\n",
      "         [ 0.0283, -0.0262, -0.0094,  0.0463,  0.0263],\n",
      "         [-0.0021, -0.0117, -0.0007, -0.0407, -0.0337]]])\n",
      "x_n_recon: tensor([[[ 0.0422,  0.0132, -0.0425, -0.0340,  0.0215],\n",
      "         [-0.0283,  0.0478,  0.0370, -0.0072, -0.0201],\n",
      "         [ 0.0464, -0.0262, -0.0357,  0.0222, -0.0641],\n",
      "         [ 0.0258, -0.0257, -0.0066,  0.0482,  0.0288],\n",
      "         [-0.0055, -0.0132, -0.0032, -0.0359, -0.0273]]])\n",
      "x_n_recon: tensor([[[ 0.0398,  0.0143, -0.0433, -0.0347,  0.0204],\n",
      "         [-0.0271,  0.0475,  0.0326, -0.0052, -0.0205],\n",
      "         [ 0.0460, -0.0258, -0.0347,  0.0241, -0.0621],\n",
      "         [ 0.0279, -0.0260, -0.0077,  0.0481,  0.0273],\n",
      "         [-0.0037, -0.0118, -0.0006, -0.0390, -0.0313]]])\n",
      "x_n_recon: tensor([[[ 0.0391,  0.0147, -0.0434, -0.0340,  0.0196],\n",
      "         [-0.0270,  0.0477,  0.0309, -0.0049, -0.0209],\n",
      "         [ 0.0457, -0.0257, -0.0341,  0.0249, -0.0620],\n",
      "         [ 0.0280, -0.0260, -0.0088,  0.0475,  0.0265],\n",
      "         [-0.0031, -0.0111, -0.0006, -0.0407, -0.0325]]])\n",
      "x_n_recon: tensor([[[ 0.0427,  0.0129, -0.0426, -0.0341,  0.0214],\n",
      "         [-0.0284,  0.0480,  0.0374, -0.0077, -0.0202],\n",
      "         [ 0.0468, -0.0263, -0.0357,  0.0217, -0.0643],\n",
      "         [ 0.0257, -0.0256, -0.0063,  0.0483,  0.0286],\n",
      "         [-0.0054, -0.0134, -0.0036, -0.0355, -0.0266]]])\n",
      "x_n_recon: tensor([[[ 0.0420,  0.0136, -0.0428, -0.0340,  0.0210],\n",
      "         [-0.0282,  0.0483,  0.0356, -0.0070, -0.0205],\n",
      "         [ 0.0467, -0.0261, -0.0351,  0.0223, -0.0635],\n",
      "         [ 0.0265, -0.0259, -0.0065,  0.0481,  0.0280],\n",
      "         [-0.0045, -0.0129, -0.0028, -0.0364, -0.0279]]])\n",
      "x_n_recon: tensor([[[ 0.0427,  0.0129, -0.0426, -0.0339,  0.0214],\n",
      "         [-0.0282,  0.0480,  0.0372, -0.0076, -0.0201],\n",
      "         [ 0.0468, -0.0262, -0.0356,  0.0219, -0.0644],\n",
      "         [ 0.0257, -0.0255, -0.0063,  0.0485,  0.0286],\n",
      "         [-0.0054, -0.0131, -0.0035, -0.0356, -0.0267]]])\n",
      "x_n_recon: tensor([[[ 0.0397,  0.0151, -0.0431, -0.0338,  0.0200],\n",
      "         [-0.0279,  0.0481,  0.0324, -0.0053, -0.0210],\n",
      "         [ 0.0459, -0.0254, -0.0345,  0.0247, -0.0624],\n",
      "         [ 0.0280, -0.0264, -0.0081,  0.0471,  0.0273],\n",
      "         [-0.0032, -0.0121, -0.0011, -0.0394, -0.0319]]])\n",
      "x_n_recon: tensor([[[ 0.0403,  0.0141, -0.0432, -0.0344,  0.0206],\n",
      "         [-0.0273,  0.0478,  0.0330, -0.0056, -0.0205],\n",
      "         [ 0.0461, -0.0258, -0.0347,  0.0239, -0.0623],\n",
      "         [ 0.0275, -0.0259, -0.0075,  0.0480,  0.0273],\n",
      "         [-0.0038, -0.0119, -0.0012, -0.0387, -0.0307]]])\n",
      "x_n_recon: tensor([[[ 0.0441,  0.0118, -0.0421, -0.0333,  0.0218],\n",
      "         [-0.0285,  0.0478,  0.0394, -0.0096, -0.0201],\n",
      "         [ 0.0470, -0.0265, -0.0364,  0.0214, -0.0657],\n",
      "         [ 0.0239, -0.0249, -0.0062,  0.0478,  0.0288],\n",
      "         [-0.0066, -0.0139, -0.0057, -0.0347, -0.0250]]])\n",
      "x_n_recon: tensor([[[ 0.0411,  0.0136, -0.0431, -0.0343,  0.0208],\n",
      "         [-0.0276,  0.0480,  0.0343, -0.0062, -0.0206],\n",
      "         [ 0.0463, -0.0260, -0.0348,  0.0230, -0.0627],\n",
      "         [ 0.0271, -0.0259, -0.0070,  0.0483,  0.0277],\n",
      "         [-0.0042, -0.0124, -0.0017, -0.0374, -0.0291]]])\n",
      "x_n_recon: tensor([[[ 0.0395,  0.0153, -0.0432, -0.0333,  0.0195],\n",
      "         [-0.0277,  0.0482,  0.0313, -0.0051, -0.0212],\n",
      "         [ 0.0459, -0.0254, -0.0340,  0.0252, -0.0623],\n",
      "         [ 0.0281, -0.0263, -0.0087,  0.0468,  0.0268],\n",
      "         [-0.0027, -0.0117, -0.0011, -0.0403, -0.0327]]])\n",
      "x_n_recon: tensor([[[ 0.0402,  0.0145, -0.0431, -0.0343,  0.0204],\n",
      "         [-0.0278,  0.0480,  0.0330, -0.0056, -0.0208],\n",
      "         [ 0.0461, -0.0256, -0.0346,  0.0241, -0.0624],\n",
      "         [ 0.0278, -0.0262, -0.0075,  0.0475,  0.0274],\n",
      "         [-0.0034, -0.0124, -0.0012, -0.0386, -0.0310]]])\n",
      "x_n_recon: tensor([[[ 0.0442,  0.0113, -0.0419, -0.0340,  0.0221],\n",
      "         [-0.0298,  0.0470,  0.0412, -0.0106, -0.0210],\n",
      "         [ 0.0470, -0.0269, -0.0370,  0.0209, -0.0659],\n",
      "         [ 0.0228, -0.0253, -0.0064,  0.0469,  0.0295],\n",
      "         [-0.0072, -0.0158, -0.0063, -0.0334, -0.0240]]])\n",
      "x_n_recon: tensor([[[ 0.0391,  0.0152, -0.0435, -0.0329,  0.0191],\n",
      "         [-0.0276,  0.0478,  0.0299, -0.0047, -0.0216],\n",
      "         [ 0.0459, -0.0256, -0.0333,  0.0257, -0.0621],\n",
      "         [ 0.0283, -0.0262, -0.0095,  0.0466,  0.0262],\n",
      "         [-0.0022, -0.0113, -0.0006, -0.0410, -0.0336]]])\n",
      "x_n_recon: tensor([[[ 0.0406,  0.0146, -0.0432, -0.0341,  0.0205],\n",
      "         [-0.0277,  0.0482,  0.0330, -0.0057, -0.0208],\n",
      "         [ 0.0462, -0.0256, -0.0345,  0.0243, -0.0625],\n",
      "         [ 0.0278, -0.0261, -0.0074,  0.0476,  0.0275],\n",
      "         [-0.0033, -0.0123, -0.0013, -0.0386, -0.0310]]])\n",
      "x_n_recon: tensor([[[ 0.0400,  0.0147, -0.0433, -0.0341,  0.0201],\n",
      "         [-0.0274,  0.0480,  0.0321, -0.0053, -0.0208],\n",
      "         [ 0.0460, -0.0256, -0.0344,  0.0246, -0.0623],\n",
      "         [ 0.0279, -0.0260, -0.0080,  0.0475,  0.0271],\n",
      "         [-0.0033, -0.0118, -0.0011, -0.0395, -0.0318]]])\n",
      "x_n_recon: tensor([[[ 0.0440,  0.0112, -0.0419, -0.0336,  0.0220],\n",
      "         [-0.0290,  0.0473,  0.0406, -0.0100, -0.0202],\n",
      "         [ 0.0467, -0.0268, -0.0370,  0.0209, -0.0660],\n",
      "         [ 0.0228, -0.0248, -0.0064,  0.0475,  0.0292],\n",
      "         [-0.0075, -0.0148, -0.0064, -0.0342, -0.0241]]])\n",
      "x_n_recon: tensor([[[ 0.0422,  0.0131, -0.0429, -0.0341,  0.0212],\n",
      "         [-0.0278,  0.0479,  0.0361, -0.0068, -0.0200],\n",
      "         [ 0.0466, -0.0260, -0.0353,  0.0224, -0.0638],\n",
      "         [ 0.0264, -0.0257, -0.0064,  0.0490,  0.0283],\n",
      "         [-0.0050, -0.0125, -0.0024, -0.0361, -0.0274]]])\n",
      "x_n_recon: tensor([[[ 0.0395,  0.0153, -0.0432, -0.0333,  0.0195],\n",
      "         [-0.0278,  0.0482,  0.0313, -0.0051, -0.0213],\n",
      "         [ 0.0460, -0.0254, -0.0340,  0.0253, -0.0623],\n",
      "         [ 0.0282, -0.0263, -0.0087,  0.0467,  0.0267],\n",
      "         [-0.0026, -0.0118, -0.0011, -0.0402, -0.0328]]])\n",
      "x_n_recon: tensor([[[ 0.0428,  0.0131, -0.0425, -0.0339,  0.0215],\n",
      "         [-0.0284,  0.0480,  0.0373, -0.0076, -0.0202],\n",
      "         [ 0.0468, -0.0261, -0.0356,  0.0220, -0.0644],\n",
      "         [ 0.0259, -0.0257, -0.0063,  0.0484,  0.0287],\n",
      "         [-0.0053, -0.0133, -0.0034, -0.0354, -0.0268]]])\n",
      "x_n_recon: tensor([[[ 0.0413,  0.0140, -0.0429, -0.0341,  0.0210],\n",
      "         [-0.0281,  0.0482,  0.0347, -0.0063, -0.0207],\n",
      "         [ 0.0463, -0.0259, -0.0349,  0.0232, -0.0628],\n",
      "         [ 0.0271, -0.0261, -0.0068,  0.0479,  0.0282],\n",
      "         [-0.0041, -0.0129, -0.0020, -0.0371, -0.0293]]])\n",
      "x_n_recon: tensor([[[ 0.0442,  0.0122, -0.0418, -0.0336,  0.0220],\n",
      "         [-0.0292,  0.0478,  0.0401, -0.0100, -0.0205],\n",
      "         [ 0.0469, -0.0267, -0.0365,  0.0212, -0.0657],\n",
      "         [ 0.0241, -0.0254, -0.0061,  0.0471,  0.0293],\n",
      "         [-0.0064, -0.0149, -0.0060, -0.0342, -0.0251]]])\n",
      "x_n_recon: tensor([[[ 0.0419,  0.0131, -0.0426, -0.0335,  0.0211],\n",
      "         [-0.0280,  0.0478,  0.0359, -0.0070, -0.0198],\n",
      "         [ 0.0463, -0.0262, -0.0353,  0.0226, -0.0640],\n",
      "         [ 0.0255, -0.0255, -0.0071,  0.0482,  0.0283],\n",
      "         [-0.0056, -0.0124, -0.0033, -0.0369, -0.0275]]])\n",
      "Epoch [2/500], Train Loss: 0.9217, Val Loss: 1.0723\n",
      "x_n_recon: tensor([[[-0.0219,  0.0221, -0.0235,  0.0265, -0.0039],\n",
      "         [-0.0048,  0.0225,  0.0488,  0.0200, -0.0122],\n",
      "         [ 0.0397, -0.0042, -0.0195,  0.0216, -0.0441],\n",
      "         [ 0.0164, -0.0315,  0.0015,  0.0277,  0.0286],\n",
      "         [-0.0238,  0.0288,  0.0274, -0.0322, -0.0214]]])\n",
      "x_n_recon: tensor([[[-0.0139,  0.0236, -0.0262,  0.0173,  0.0006],\n",
      "         [-0.0057,  0.0293,  0.0454,  0.0196, -0.0115],\n",
      "         [ 0.0407, -0.0079, -0.0198,  0.0220, -0.0432],\n",
      "         [ 0.0208, -0.0287,  0.0033,  0.0331,  0.0284],\n",
      "         [-0.0161,  0.0237,  0.0228, -0.0331, -0.0251]]])\n",
      "x_n_recon: tensor([[[-0.0158,  0.0232, -0.0253,  0.0198, -0.0002],\n",
      "         [-0.0054,  0.0276,  0.0467,  0.0194, -0.0118],\n",
      "         [ 0.0404, -0.0068, -0.0200,  0.0220, -0.0433],\n",
      "         [ 0.0197, -0.0296,  0.0029,  0.0317,  0.0286],\n",
      "         [-0.0182,  0.0251,  0.0240, -0.0326, -0.0240]]])\n",
      "x_n_recon: tensor([[[-0.0233,  0.0218, -0.0229,  0.0280, -0.0047],\n",
      "         [-0.0044,  0.0212,  0.0493,  0.0199, -0.0122],\n",
      "         [ 0.0396, -0.0035, -0.0197,  0.0213, -0.0444],\n",
      "         [ 0.0157, -0.0319,  0.0011,  0.0269,  0.0283],\n",
      "         [-0.0252,  0.0296,  0.0279, -0.0325, -0.0208]]])\n",
      "x_n_recon: tensor([[[-0.0155, -0.0012, -0.0188,  0.0086, -0.0093],\n",
      "         [-0.0112,  0.0352,  0.0380, -0.0132, -0.0299],\n",
      "         [ 0.0330, -0.0404, -0.0264,  0.0095, -0.0311],\n",
      "         [-0.0040, -0.0101, -0.0147,  0.0151,  0.0061],\n",
      "         [-0.0329, -0.0026, -0.0081, -0.0237, -0.0066]]])\n",
      "x_n_recon: tensor([[[-0.0266, -0.0099, -0.0099,  0.0101, -0.0236],\n",
      "         [-0.0144,  0.0282,  0.0353, -0.0318, -0.0406],\n",
      "         [ 0.0254, -0.0586, -0.0343,  0.0048, -0.0270],\n",
      "         [-0.0244,  0.0019, -0.0351, -0.0055, -0.0092],\n",
      "         [-0.0513, -0.0151, -0.0197, -0.0211, -0.0002]]])\n",
      "x_n_recon: tensor([[[-0.0209, -0.0057, -0.0145,  0.0098, -0.0164],\n",
      "         [-0.0129,  0.0319,  0.0368, -0.0221, -0.0354],\n",
      "         [ 0.0291, -0.0492, -0.0300,  0.0076, -0.0290],\n",
      "         [-0.0134, -0.0049, -0.0249,  0.0050, -0.0011],\n",
      "         [-0.0417, -0.0088, -0.0135, -0.0223, -0.0033]]])\n",
      "x_n_recon: tensor([[[-0.0148,  0.0233, -0.0256,  0.0186,  0.0002],\n",
      "         [-0.0055,  0.0285,  0.0459,  0.0193, -0.0119],\n",
      "         [ 0.0406, -0.0073, -0.0199,  0.0218, -0.0431],\n",
      "         [ 0.0203, -0.0292,  0.0032,  0.0324,  0.0282],\n",
      "         [-0.0171,  0.0243,  0.0233, -0.0328, -0.0245]]])\n",
      "x_n_recon: tensor([[[-0.0235,  0.0219, -0.0228,  0.0282, -0.0048],\n",
      "         [-0.0044,  0.0211,  0.0494,  0.0199, -0.0122],\n",
      "         [ 0.0396, -0.0034, -0.0196,  0.0213, -0.0444],\n",
      "         [ 0.0156, -0.0320,  0.0010,  0.0268,  0.0283],\n",
      "         [-0.0254,  0.0297,  0.0280, -0.0325, -0.0208]]])\n",
      "x_n_recon: tensor([[[-0.0123,  0.0236, -0.0264,  0.0161,  0.0017],\n",
      "         [-0.0057,  0.0308,  0.0449,  0.0192, -0.0117],\n",
      "         [ 0.0405, -0.0085, -0.0199,  0.0221, -0.0427],\n",
      "         [ 0.0217, -0.0285,  0.0037,  0.0339,  0.0286],\n",
      "         [-0.0150,  0.0225,  0.0220, -0.0326, -0.0255]]])\n",
      "x_n_recon: tensor([[[-0.0201,  0.0222, -0.0241,  0.0244, -0.0027],\n",
      "         [-0.0049,  0.0240,  0.0485,  0.0198, -0.0118],\n",
      "         [ 0.0400, -0.0050, -0.0198,  0.0216, -0.0438],\n",
      "         [ 0.0174, -0.0309,  0.0022,  0.0288,  0.0289],\n",
      "         [-0.0223,  0.0277,  0.0264, -0.0322, -0.0220]]])\n",
      "x_n_recon: tensor([[[-0.0235,  0.0216, -0.0225,  0.0285, -0.0046],\n",
      "         [-0.0041,  0.0207,  0.0499,  0.0195, -0.0122],\n",
      "         [ 0.0399, -0.0030, -0.0200,  0.0213, -0.0445],\n",
      "         [ 0.0153, -0.0321,  0.0011,  0.0266,  0.0281],\n",
      "         [-0.0259,  0.0300,  0.0279, -0.0324, -0.0206]]])\n",
      "x_n_recon: tensor([[[-0.0393, -0.0187, -0.0017,  0.0135, -0.0380],\n",
      "         [-0.0162,  0.0195,  0.0346, -0.0505, -0.0507],\n",
      "         [ 0.0183, -0.0731, -0.0429, -0.0007, -0.0237],\n",
      "         [-0.0438,  0.0131, -0.0539, -0.0261, -0.0247],\n",
      "         [-0.0700, -0.0270, -0.0277, -0.0161,  0.0077]]])\n",
      "x_n_recon: tensor([[[-0.0338, -0.0150, -0.0051,  0.0125, -0.0320],\n",
      "         [-0.0159,  0.0229,  0.0353, -0.0425, -0.0468],\n",
      "         [ 0.0214, -0.0672, -0.0387,  0.0021, -0.0250],\n",
      "         [-0.0354,  0.0074, -0.0461, -0.0176, -0.0175],\n",
      "         [-0.0621, -0.0220, -0.0240, -0.0182,  0.0045]]])\n",
      "x_n_recon: tensor([[[-0.0392, -0.0186, -0.0016,  0.0131, -0.0383],\n",
      "         [-0.0165,  0.0192,  0.0343, -0.0508, -0.0512],\n",
      "         [ 0.0184, -0.0733, -0.0429, -0.0007, -0.0235],\n",
      "         [-0.0439,  0.0127, -0.0545, -0.0264, -0.0251],\n",
      "         [-0.0696, -0.0274, -0.0277, -0.0161,  0.0077]]])\n",
      "x_n_recon: tensor([[[-0.0190,  0.0225, -0.0245,  0.0230, -0.0021],\n",
      "         [-0.0050,  0.0250,  0.0476,  0.0197, -0.0120],\n",
      "         [ 0.0403, -0.0055, -0.0198,  0.0216, -0.0437],\n",
      "         [ 0.0180, -0.0305,  0.0023,  0.0297,  0.0284],\n",
      "         [-0.0209,  0.0270,  0.0256, -0.0326, -0.0226]]])\n",
      "x_n_recon: tensor([[[-0.0140,  0.0234, -0.0258,  0.0177,  0.0007],\n",
      "         [-0.0057,  0.0292,  0.0455,  0.0191, -0.0120],\n",
      "         [ 0.0405, -0.0078, -0.0199,  0.0220, -0.0431],\n",
      "         [ 0.0205, -0.0289,  0.0031,  0.0329,  0.0283],\n",
      "         [-0.0164,  0.0236,  0.0226, -0.0328, -0.0249]]])\n",
      "x_n_recon: tensor([[[-0.0219, -0.0061, -0.0135,  0.0091, -0.0178],\n",
      "         [-0.0127,  0.0311,  0.0363, -0.0244, -0.0364],\n",
      "         [ 0.0284, -0.0514, -0.0310,  0.0068, -0.0287],\n",
      "         [-0.0159, -0.0032, -0.0272,  0.0034, -0.0029],\n",
      "         [-0.0435, -0.0097, -0.0155, -0.0230, -0.0031]]])\n",
      "x_n_recon: tensor([[[-0.0078,  0.0090, -0.0258,  0.0059,  0.0026],\n",
      "         [-0.0079,  0.0412,  0.0398,  0.0049, -0.0184],\n",
      "         [ 0.0365, -0.0254, -0.0227,  0.0126, -0.0350],\n",
      "         [ 0.0166, -0.0196,  0.0029,  0.0308,  0.0198],\n",
      "         [-0.0158,  0.0078,  0.0049, -0.0250, -0.0152]]])\n",
      "x_n_recon: tensor([[[-0.0171, -0.0022, -0.0175,  0.0087, -0.0113],\n",
      "         [-0.0118,  0.0341,  0.0377, -0.0159, -0.0316],\n",
      "         [ 0.0318, -0.0430, -0.0275,  0.0088, -0.0305],\n",
      "         [-0.0067, -0.0085, -0.0177,  0.0122,  0.0041],\n",
      "         [-0.0355, -0.0044, -0.0098, -0.0235, -0.0057]]])\n",
      "x_n_recon: tensor([[[-0.0134,  0.0024, -0.0208,  0.0078, -0.0048],\n",
      "         [-0.0105,  0.0365,  0.0397, -0.0077, -0.0262],\n",
      "         [ 0.0336, -0.0356, -0.0256,  0.0101, -0.0323],\n",
      "         [ 0.0027, -0.0136, -0.0088,  0.0197,  0.0117],\n",
      "         [-0.0280,  0.0005, -0.0037, -0.0237, -0.0092]]])\n",
      "x_n_recon: tensor([[[-0.0046,  0.0208, -0.0291,  0.0061,  0.0077],\n",
      "         [-0.0059,  0.0400,  0.0416,  0.0172, -0.0104],\n",
      "         [ 0.0400, -0.0143, -0.0211,  0.0177, -0.0397],\n",
      "         [ 0.0257, -0.0241,  0.0094,  0.0381,  0.0276],\n",
      "         [-0.0088,  0.0153,  0.0152, -0.0296, -0.0253]]])\n",
      "x_n_recon: tensor([[[-0.0206,  0.0220, -0.0238,  0.0251, -0.0028],\n",
      "         [-0.0047,  0.0235,  0.0490,  0.0195, -0.0119],\n",
      "         [ 0.0399, -0.0046, -0.0201,  0.0217, -0.0439],\n",
      "         [ 0.0170, -0.0311,  0.0020,  0.0284,  0.0289],\n",
      "         [-0.0229,  0.0280,  0.0266, -0.0322, -0.0217]]])\n",
      "x_n_recon: tensor([[[-0.0079,  0.0237, -0.0281,  0.0107,  0.0043],\n",
      "         [-0.0059,  0.0353,  0.0425,  0.0193, -0.0111],\n",
      "         [ 0.0404, -0.0112, -0.0197,  0.0213, -0.0418],\n",
      "         [ 0.0248, -0.0268,  0.0053,  0.0368,  0.0285],\n",
      "         [-0.0105,  0.0192,  0.0193, -0.0325, -0.0274]]])\n",
      "x_n_recon: tensor([[[-0.0224,  0.0217, -0.0233,  0.0268, -0.0040],\n",
      "         [-0.0045,  0.0220,  0.0495,  0.0198, -0.0120],\n",
      "         [ 0.0399, -0.0038, -0.0200,  0.0214, -0.0442],\n",
      "         [ 0.0162, -0.0317,  0.0016,  0.0274,  0.0286],\n",
      "         [-0.0244,  0.0292,  0.0274, -0.0324, -0.0210]]])\n",
      "x_n_recon: tensor([[[-0.0340, -0.0149, -0.0049,  0.0115, -0.0328],\n",
      "         [-0.0156,  0.0226,  0.0345, -0.0435, -0.0475],\n",
      "         [ 0.0215, -0.0680, -0.0396,  0.0011, -0.0252],\n",
      "         [-0.0363,  0.0087, -0.0473, -0.0182, -0.0191],\n",
      "         [-0.0623, -0.0225, -0.0249, -0.0186,  0.0045]]])\n",
      "x_n_recon: tensor([[[-0.0110,  0.0237, -0.0268,  0.0145,  0.0024],\n",
      "         [-0.0059,  0.0319,  0.0441,  0.0192, -0.0115],\n",
      "         [ 0.0405, -0.0092, -0.0198,  0.0221, -0.0426],\n",
      "         [ 0.0225, -0.0280,  0.0040,  0.0348,  0.0285],\n",
      "         [-0.0137,  0.0216,  0.0212, -0.0328, -0.0262]]])\n",
      "x_n_recon: tensor([[[-0.0203,  0.0222, -0.0237,  0.0249, -0.0026],\n",
      "         [-0.0048,  0.0237,  0.0489,  0.0194, -0.0120],\n",
      "         [ 0.0400, -0.0046, -0.0201,  0.0219, -0.0439],\n",
      "         [ 0.0171, -0.0311,  0.0020,  0.0285,  0.0288],\n",
      "         [-0.0228,  0.0279,  0.0264, -0.0321, -0.0219]]])\n",
      "x_n_recon: tensor([[[-0.0441, -0.0211,  0.0015,  0.0144, -0.0437],\n",
      "         [-0.0173,  0.0161,  0.0346, -0.0583, -0.0558],\n",
      "         [ 0.0153, -0.0784, -0.0465, -0.0033, -0.0217],\n",
      "         [-0.0511,  0.0172, -0.0615, -0.0346, -0.0310],\n",
      "         [-0.0764, -0.0326, -0.0311, -0.0136,  0.0111]]])\n",
      "x_n_recon: tensor([[[-0.0048,  0.0212, -0.0287,  0.0072,  0.0071],\n",
      "         [-0.0060,  0.0392,  0.0416,  0.0175, -0.0111],\n",
      "         [ 0.0395, -0.0138, -0.0209,  0.0186, -0.0398],\n",
      "         [ 0.0256, -0.0250,  0.0081,  0.0379,  0.0279],\n",
      "         [-0.0087,  0.0156,  0.0158, -0.0300, -0.0256]]])\n",
      "x_n_recon: tensor([[[-0.0382, -0.0179, -0.0022,  0.0127, -0.0378],\n",
      "         [-0.0161,  0.0195,  0.0344, -0.0499, -0.0511],\n",
      "         [ 0.0194, -0.0729, -0.0423, -0.0008, -0.0240],\n",
      "         [-0.0425,  0.0120, -0.0536, -0.0250, -0.0243],\n",
      "         [-0.0685, -0.0263, -0.0274, -0.0170,  0.0072]]])\n",
      "x_n_recon: tensor([[[-0.0049,  0.0204, -0.0288,  0.0061,  0.0074],\n",
      "         [-0.0060,  0.0399,  0.0413,  0.0168, -0.0112],\n",
      "         [ 0.0397, -0.0145, -0.0210,  0.0174, -0.0393],\n",
      "         [ 0.0255, -0.0244,  0.0090,  0.0378,  0.0272],\n",
      "         [-0.0086,  0.0149,  0.0149, -0.0296, -0.0251]]])\n",
      "Epoch [3/500], Train Loss: 0.9287, Val Loss: 0.7615\n",
      "x_n_recon: tensor([[[ 0.0139,  0.0130, -0.0152,  0.0132,  0.0075],\n",
      "         [ 0.0148,  0.0329,  0.0272,  0.0135, -0.0006],\n",
      "         [ 0.0371,  0.0034, -0.0086,  0.0090, -0.0309],\n",
      "         [ 0.0512, -0.0188,  0.0227,  0.0294,  0.0161],\n",
      "         [ 0.0178,  0.0324,  0.0252, -0.0074, -0.0106]]])\n",
      "x_n_recon: tensor([[[ 0.0130,  0.0087, -0.0158,  0.0157,  0.0064],\n",
      "         [ 0.0182,  0.0270,  0.0275,  0.0155,  0.0025],\n",
      "         [ 0.0388,  0.0029, -0.0040,  0.0037, -0.0307],\n",
      "         [ 0.0529, -0.0214,  0.0292,  0.0249,  0.0107],\n",
      "         [ 0.0205,  0.0391,  0.0337, -0.0004, -0.0119]]])\n",
      "x_n_recon: tensor([[[ 0.0202,  0.0113, -0.0181,  0.0078,  0.0184],\n",
      "         [ 0.0081,  0.0542,  0.0355,  0.0087, -0.0063],\n",
      "         [ 0.0344,  0.0021, -0.0276,  0.0076, -0.0286],\n",
      "         [ 0.0445, -0.0094,  0.0250,  0.0297,  0.0259],\n",
      "         [ 0.0152,  0.0175, -0.0011, -0.0132, -0.0015]]])\n",
      "x_n_recon: tensor([[[ 3.6697e-03, -1.0913e-02, -5.8669e-03,  2.4494e-02,  1.1018e-03],\n",
      "         [ 2.4789e-02,  1.5995e-03,  3.5899e-02,  1.8626e-02,  2.5874e-02],\n",
      "         [ 3.2680e-02, -3.5902e-06, -1.8265e-03, -1.1127e-02, -3.2832e-02],\n",
      "         [ 4.0622e-02, -2.1415e-02,  5.2717e-02,  4.8572e-03, -4.7021e-03],\n",
      "         [ 1.8004e-02,  5.6010e-02,  4.8490e-02,  2.1391e-02, -1.2559e-02]]])\n",
      "x_n_recon: tensor([[[ 0.0324, -0.0025, -0.0205,  0.0067,  0.0337],\n",
      "         [ 0.0180,  0.0778,  0.0439,  0.0008, -0.0036],\n",
      "         [ 0.0322, -0.0004, -0.0438, -0.0026, -0.0197],\n",
      "         [ 0.0666, -0.0025,  0.0455,  0.0241,  0.0338],\n",
      "         [ 0.0196,  0.0113, -0.0080,  0.0005,  0.0107]]])\n",
      "x_n_recon: tensor([[[ 0.0192,  0.0119, -0.0179,  0.0078,  0.0179],\n",
      "         [ 0.0082,  0.0526,  0.0357,  0.0093, -0.0054],\n",
      "         [ 0.0342,  0.0024, -0.0272,  0.0080, -0.0292],\n",
      "         [ 0.0439, -0.0099,  0.0246,  0.0303,  0.0258],\n",
      "         [ 0.0145,  0.0183, -0.0002, -0.0136, -0.0023]]])\n",
      "x_n_recon: tensor([[[ 0.0317, -0.0012, -0.0205,  0.0069,  0.0325],\n",
      "         [ 0.0170,  0.0760,  0.0432,  0.0014, -0.0042],\n",
      "         [ 0.0323, -0.0003, -0.0423, -0.0016, -0.0204],\n",
      "         [ 0.0649, -0.0034,  0.0436,  0.0246,  0.0334],\n",
      "         [ 0.0195,  0.0116, -0.0074, -0.0006,  0.0095]]])\n",
      "x_n_recon: tensor([[[ 0.0123,  0.0150, -0.0166,  0.0074,  0.0117],\n",
      "         [ 0.0080,  0.0421,  0.0318,  0.0130, -0.0043],\n",
      "         [ 0.0337,  0.0037, -0.0216,  0.0104, -0.0301],\n",
      "         [ 0.0436, -0.0152,  0.0205,  0.0311,  0.0232],\n",
      "         [ 0.0141,  0.0229,  0.0097, -0.0153, -0.0066]]])\n",
      "x_n_recon: tensor([[[ 0.0241,  0.0078, -0.0194,  0.0077,  0.0228],\n",
      "         [ 0.0100,  0.0610,  0.0373,  0.0073, -0.0064],\n",
      "         [ 0.0334,  0.0013, -0.0319,  0.0061, -0.0261],\n",
      "         [ 0.0501, -0.0076,  0.0291,  0.0278,  0.0287],\n",
      "         [ 0.0171,  0.0145, -0.0036, -0.0103,  0.0008]]])\n",
      "x_n_recon: tensor([[[ 0.0094,  0.0009, -0.0120,  0.0194,  0.0042],\n",
      "         [ 0.0213,  0.0172,  0.0308,  0.0169,  0.0115],\n",
      "         [ 0.0368,  0.0018, -0.0021, -0.0032, -0.0311],\n",
      "         [ 0.0491, -0.0220,  0.0400,  0.0168,  0.0041],\n",
      "         [ 0.0202,  0.0467,  0.0411,  0.0098, -0.0122]]])\n",
      "x_n_recon: tensor([[[ 0.0243,  0.0086, -0.0188,  0.0082,  0.0224],\n",
      "         [ 0.0102,  0.0601,  0.0376,  0.0071, -0.0059],\n",
      "         [ 0.0338,  0.0014, -0.0315,  0.0063, -0.0271],\n",
      "         [ 0.0489, -0.0075,  0.0288,  0.0285,  0.0283],\n",
      "         [ 0.0166,  0.0154, -0.0039, -0.0107,  0.0006]]])\n",
      "x_n_recon: tensor([[[ 0.0111,  0.0042, -0.0143,  0.0177,  0.0051],\n",
      "         [ 0.0200,  0.0217,  0.0291,  0.0167,  0.0074],\n",
      "         [ 0.0381,  0.0022, -0.0021, -0.0009, -0.0307],\n",
      "         [ 0.0516, -0.0221,  0.0362,  0.0200,  0.0067],\n",
      "         [ 0.0211,  0.0439,  0.0392,  0.0063, -0.0123]]])\n",
      "x_n_recon: tensor([[[ 3.9596e-03, -1.0099e-02, -6.1577e-03,  2.4288e-02,  1.2820e-03],\n",
      "         [ 2.4681e-02,  2.4868e-03,  3.5452e-02,  1.8394e-02,  2.4881e-02],\n",
      "         [ 3.2959e-02,  9.5704e-05, -1.7408e-03, -1.0703e-02, -3.2701e-02],\n",
      "         [ 4.1107e-02, -2.1478e-02,  5.1788e-02,  5.6953e-03, -4.2063e-03],\n",
      "         [ 1.8030e-02,  5.5620e-02,  4.8058e-02,  2.0498e-02, -1.2406e-02]]])\n",
      "x_n_recon: tensor([[[ 2.9287e-02,  2.7903e-03, -2.0265e-02,  7.3384e-03,  2.8663e-02],\n",
      "         [ 1.3787e-02,  7.0501e-02,  4.0651e-02,  3.8883e-03, -5.6856e-03],\n",
      "         [ 3.2617e-02,  2.9802e-08, -3.8354e-02,  1.7356e-03, -2.2587e-02],\n",
      "         [ 5.8320e-02, -4.8685e-03,  3.7153e-02,  2.5259e-02,  3.1683e-02],\n",
      "         [ 1.9056e-02,  1.2040e-02, -6.7427e-03, -4.6083e-03,  6.0443e-03]]])\n",
      "x_n_recon: tensor([[[ 0.0282,  0.0038, -0.0201,  0.0078,  0.0273],\n",
      "         [ 0.0131,  0.0681,  0.0398,  0.0051, -0.0057],\n",
      "         [ 0.0326,  0.0006, -0.0368,  0.0038, -0.0236],\n",
      "         [ 0.0564, -0.0057,  0.0345,  0.0261,  0.0312],\n",
      "         [ 0.0185,  0.0124, -0.0061, -0.0067,  0.0040]]])\n",
      "x_n_recon: tensor([[[ 0.0110,  0.0040, -0.0142,  0.0178,  0.0049],\n",
      "         [ 0.0201,  0.0214,  0.0296,  0.0169,  0.0078],\n",
      "         [ 0.0378,  0.0022, -0.0023, -0.0009, -0.0307],\n",
      "         [ 0.0515, -0.0223,  0.0367,  0.0198,  0.0068],\n",
      "         [ 0.0211,  0.0439,  0.0394,  0.0069, -0.0124]]])\n",
      "x_n_recon: tensor([[[ 0.0292,  0.0031, -0.0199,  0.0077,  0.0282],\n",
      "         [ 0.0137,  0.0695,  0.0406,  0.0041, -0.0056],\n",
      "         [ 0.0325,  0.0002, -0.0379,  0.0025, -0.0232],\n",
      "         [ 0.0576, -0.0052,  0.0362,  0.0257,  0.0315],\n",
      "         [ 0.0189,  0.0123, -0.0067, -0.0053,  0.0054]]])\n",
      "x_n_recon: tensor([[[ 0.0285,  0.0034, -0.0199,  0.0078,  0.0276],\n",
      "         [ 0.0132,  0.0683,  0.0403,  0.0047, -0.0056],\n",
      "         [ 0.0323,  0.0006, -0.0371,  0.0035, -0.0235],\n",
      "         [ 0.0569, -0.0058,  0.0350,  0.0260,  0.0313],\n",
      "         [ 0.0187,  0.0123, -0.0061, -0.0062,  0.0045]]])\n",
      "x_n_recon: tensor([[[ 0.0106,  0.0032, -0.0139,  0.0181,  0.0047],\n",
      "         [ 0.0202,  0.0203,  0.0300,  0.0171,  0.0089],\n",
      "         [ 0.0376,  0.0021, -0.0023, -0.0014, -0.0309],\n",
      "         [ 0.0510, -0.0223,  0.0374,  0.0189,  0.0061],\n",
      "         [ 0.0209,  0.0445,  0.0400,  0.0076, -0.0124]]])\n",
      "x_n_recon: tensor([[[ 0.0187,  0.0124, -0.0177,  0.0075,  0.0170],\n",
      "         [ 0.0079,  0.0517,  0.0350,  0.0094, -0.0059],\n",
      "         [ 0.0345,  0.0022, -0.0265,  0.0080, -0.0291],\n",
      "         [ 0.0435, -0.0105,  0.0239,  0.0303,  0.0251],\n",
      "         [ 0.0147,  0.0186,  0.0004, -0.0139, -0.0025]]])\n",
      "x_n_recon: tensor([[[ 2.3187e-02,  9.1628e-03, -1.8812e-02,  8.0552e-03,  2.1520e-02],\n",
      "         [ 9.4751e-03,  5.8716e-02,  3.6898e-02,  7.6740e-03, -6.3400e-03],\n",
      "         [ 3.3547e-02,  1.6192e-03, -3.0490e-02,  6.6634e-03, -2.7257e-02],\n",
      "         [ 4.7985e-02, -8.1545e-03,  2.7737e-02,  2.8545e-02,  2.7912e-02],\n",
      "         [ 1.6560e-02,  1.5577e-02, -3.0608e-03, -1.1265e-02, -1.8507e-05]]])\n",
      "x_n_recon: tensor([[[ 0.0096,  0.0011, -0.0124,  0.0191,  0.0042],\n",
      "         [ 0.0213,  0.0169,  0.0304,  0.0169,  0.0116],\n",
      "         [ 0.0374,  0.0015, -0.0017, -0.0033, -0.0314],\n",
      "         [ 0.0493, -0.0221,  0.0394,  0.0169,  0.0037],\n",
      "         [ 0.0202,  0.0471,  0.0416,  0.0093, -0.0122]]])\n",
      "x_n_recon: tensor([[[ 0.0010, -0.0162, -0.0035,  0.0268, -0.0002],\n",
      "         [ 0.0262, -0.0051,  0.0382,  0.0196,  0.0319],\n",
      "         [ 0.0305, -0.0009, -0.0017, -0.0144, -0.0334],\n",
      "         [ 0.0369, -0.0208,  0.0582, -0.0008, -0.0083],\n",
      "         [ 0.0171,  0.0599,  0.0520,  0.0266, -0.0129]]])\n",
      "x_n_recon: tensor([[[ 9.8384e-04, -1.5810e-02, -3.6024e-03,  2.6557e-02, -9.5222e-05],\n",
      "         [ 2.6093e-02, -4.7882e-03,  3.8151e-02,  1.9663e-02,  3.1727e-02],\n",
      "         [ 3.0415e-02, -1.0147e-03, -1.6500e-03, -1.4484e-02, -3.3358e-02],\n",
      "         [ 3.7150e-02, -2.0999e-02,  5.8128e-02, -4.9898e-04, -7.7795e-03],\n",
      "         [ 1.7120e-02,  5.9706e-02,  5.1977e-02,  2.6512e-02, -1.2872e-02]]])\n",
      "x_n_recon: tensor([[[-0.0011, -0.0198, -0.0019,  0.0286, -0.0007],\n",
      "         [ 0.0272, -0.0090,  0.0395,  0.0201,  0.0353],\n",
      "         [ 0.0288, -0.0016, -0.0015, -0.0168, -0.0332],\n",
      "         [ 0.0346, -0.0203,  0.0621, -0.0046, -0.0102],\n",
      "         [ 0.0162,  0.0623,  0.0540,  0.0301, -0.0127]]])\n",
      "x_n_recon: tensor([[[ 3.1595e-02, -1.4797e-05, -2.0316e-02,  6.9732e-03,  3.1530e-02],\n",
      "         [ 1.6395e-02,  7.4855e-02,  4.2514e-02,  1.9053e-03, -4.4093e-03],\n",
      "         [ 3.2772e-02, -4.1689e-04, -4.1442e-02, -7.9691e-04, -2.1105e-02],\n",
      "         [ 6.3031e-02, -3.5689e-03,  4.1972e-02,  2.5079e-02,  3.2737e-02],\n",
      "         [ 1.9391e-02,  1.1786e-02, -7.7129e-03, -1.7638e-03,  8.5913e-03]]])\n",
      "x_n_recon: tensor([[[ 0.0270,  0.0054, -0.0199,  0.0079,  0.0256],\n",
      "         [ 0.0116,  0.0658,  0.0388,  0.0060, -0.0065],\n",
      "         [ 0.0325,  0.0005, -0.0350,  0.0048, -0.0243],\n",
      "         [ 0.0539, -0.0064,  0.0320,  0.0262,  0.0305],\n",
      "         [ 0.0185,  0.0127, -0.0055, -0.0079,  0.0029]]])\n",
      "x_n_recon: tensor([[[ 0.0126,  0.0073, -0.0157,  0.0164,  0.0065],\n",
      "         [ 0.0191,  0.0256,  0.0277,  0.0160,  0.0034],\n",
      "         [ 0.0391,  0.0030, -0.0029,  0.0019, -0.0307],\n",
      "         [ 0.0530, -0.0217,  0.0313,  0.0235,  0.0092],\n",
      "         [ 0.0211,  0.0410,  0.0357,  0.0014, -0.0121]]])\n",
      "x_n_recon: tensor([[[ 0.0323, -0.0018, -0.0204,  0.0071,  0.0331],\n",
      "         [ 0.0177,  0.0769,  0.0437,  0.0010, -0.0039],\n",
      "         [ 0.0323, -0.0003, -0.0430, -0.0020, -0.0203],\n",
      "         [ 0.0657, -0.0030,  0.0445,  0.0246,  0.0336],\n",
      "         [ 0.0195,  0.0117, -0.0078, -0.0002,  0.0101]]])\n",
      "x_n_recon: tensor([[[ 0.0067, -0.0048, -0.0088,  0.0220,  0.0028],\n",
      "         [ 0.0232,  0.0095,  0.0330,  0.0174,  0.0183],\n",
      "         [ 0.0351,  0.0010, -0.0019, -0.0071, -0.0319],\n",
      "         [ 0.0448, -0.0217,  0.0459,  0.0112, -0.0006],\n",
      "         [ 0.0190,  0.0515,  0.0446,  0.0151, -0.0122]]])\n",
      "x_n_recon: tensor([[[ 0.0157,  0.0140, -0.0175,  0.0071,  0.0145],\n",
      "         [ 0.0077,  0.0476,  0.0338,  0.0112, -0.0054],\n",
      "         [ 0.0339,  0.0031, -0.0247,  0.0087, -0.0295],\n",
      "         [ 0.0431, -0.0130,  0.0222,  0.0307,  0.0242],\n",
      "         [ 0.0146,  0.0202,  0.0043, -0.0149, -0.0043]]])\n",
      "x_n_recon: tensor([[[ 0.0272,  0.0050, -0.0201,  0.0075,  0.0260],\n",
      "         [ 0.0120,  0.0667,  0.0388,  0.0057, -0.0061],\n",
      "         [ 0.0330,  0.0004, -0.0356,  0.0043, -0.0240],\n",
      "         [ 0.0546, -0.0060,  0.0329,  0.0263,  0.0304],\n",
      "         [ 0.0183,  0.0126, -0.0059, -0.0077,  0.0033]]])\n",
      "Epoch [4/500], Train Loss: 0.7119, Val Loss: 0.5899\n"
     ]
    }
   ],
   "source": [
    "###TRAIN MODEL\n",
    "\n",
    "def loss_function(x_n, x_n_recon, r_n, r_n_recon, mu, log_var):\n",
    "    # Ensure x_n and r_n are unsqueezed if needed (depends on data shape handling in other parts of your code)\n",
    "    x_n = torch.unsqueeze(x_n, dim=0) if len(x_n.shape) < 3 else x_n\n",
    "    r_n = torch.unsqueeze(r_n, dim=0) if len(r_n.shape) < 3 else r_n\n",
    "\n",
    "    # Calculate the mean squared error, normalized by the number of elements (H*W)\n",
    "    recon_loss_x = F.mse_loss(x_n_recon, x_n, reduction='mean') / (H * W)\n",
    "    recon_loss_r = F.mse_loss(r_n_recon, r_n, reduction='mean')\n",
    "\n",
    "    # Calculate the Kullback-Leibler divergence\n",
    "    kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "\n",
    "    # Combine the losses with the scaling factors\n",
    "    total_loss = recon_loss_x + alpha * recon_loss_r + beta * kl_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        batch_size = x.shape[0] #batch_size, context_length, num_surfaces, H, W = x.shape\n",
    "        \n",
    "        # Generate a random day t to split the sequence into context and future\n",
    "        t = batch_size - num_surfaces - 1\n",
    "        #print(t)\n",
    "\n",
    "        x_c, x_n = x[:t, :], x[t:, :]\n",
    "        y_c, y_n = y[:t, :], y[t:, :]\n",
    "            \n",
    "        r_n = y_n[:, :, 0]\n",
    "        \n",
    "        x_n_recon, r_n_recon, mu, log_var = model(x, y, x_c, y_c)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = loss_function(x_n[0], x_n_recon, r_n[0], r_n_recon, mu, log_var)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x, y = batch\n",
    "            batch_size = x.shape[0]  # Number of days in the sequence\n",
    "            \n",
    "            # Generate a random day t to split the sequence into context and future\n",
    "            #t = generate_random_day(batch_size)\n",
    "            t = batch_size - num_surfaces - 1\n",
    "            \n",
    "            x_c, x_n = x[:t, :], x[t:, :]\n",
    "            y_c, y_n = y[:t, :], y[t:, :]\n",
    "            \n",
    "            # Extract the log return feature from y_n\n",
    "            r_n = y_n[:, :, 0]\n",
    "            \n",
    "            x_n_recon, r_n_recon, mu, log_var = model(x, y, x_c, y_c)\n",
    "            print(f\"x_n_recon: {x_n_recon}\")\n",
    "            \n",
    "            # Compute the loss\n",
    "            loss = loss_function(x_n[0], x_n_recon, r_n[0], r_n_recon, mu, log_var)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    # Print the losses for each epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}\")\n",
    "    \n",
    "    # Save the best model based on validation loss\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "# Testing\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()\n",
    "#test_loss = 0.0\n",
    "#with torch.no_grad():\n",
    " #   for batch in test_loader:\n",
    "  #      x, y = batch\n",
    "   #     batch_size = x.shape[0]  # Number of days in the sequence\n",
    "    #    \n",
    "        # Generate a random day t to split the sequence into context and future\n",
    "     #   t = batch_size - num_surfaces - 1\n",
    "      #  \n",
    "       # x_c, x_n = x[:, :t], x[:, t:]\n",
    "        #y_c, y_n = y[:, :t], y[:, t:]\n",
    "        \n",
    "        # Extract the log return feature from y_n\n",
    "        #r_n = y_n[:, :, 0]\n",
    "        \n",
    "        #x_n_recon, r_n_recon, mu, log_var = model(x, y, x_c, y_c)\n",
    "        \n",
    "        # Compute the loss\n",
    "        #loss = loss_function(x_n[0], x_n_recon, r_n[0], r_n_recon, mu, log_var)\n",
    "        \n",
    "        #test_loss += loss.item()\n",
    "\n",
    "#ßprint(f\"Test Loss: {test_loss/len(test_loader):.4f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2c955b-9238-4128-9dc3-2274ab6dadff",
   "metadata": {},
   "outputs": [],
   "source": [
    "###HYPERPARAMETER TUNING\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import ParameterGrid, KFold\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 25\n",
    "context_size = 5\n",
    "input_size = 1\n",
    "output_size = 5\n",
    "\n",
    "# Reshape the input data to the desired 5-dimensional shape\n",
    "batch_size_train = X_train.shape[0]\n",
    "batch_size_test = X_test.shape[0]\n",
    "\n",
    "sequence_length = 1\n",
    "num_surfaces = 1  # the number of surfaces to generate\n",
    "H = 5  # Height of the IV surface grid\n",
    "W = 5  # Width of the IV surface grid\n",
    "\n",
    "X_train_reshaped = X_train.reshape(batch_size_train, H, W)\n",
    "X_test_reshaped = X_test.reshape(batch_size_test, H, W)\n",
    "\n",
    "extra_features_size = 3\n",
    "y_train_reshaped = y_train.reshape(y_train.shape[0], 1, extra_features_size)\n",
    "y_test_reshaped = y_test.reshape(y_test.shape[0], 1, extra_features_size)\n",
    "\n",
    "train_data = TensorDataset(torch.Tensor(X_train_reshaped), torch.Tensor(y_train_reshaped))\n",
    "test_data = TensorDataset(torch.Tensor(X_test_reshaped), torch.Tensor(y_test_reshaped))\n",
    "\n",
    "# Create the model\n",
    "model = CVAE(input_size, hidden_size, latent_size, context_size, input_size, num_surfaces)\n",
    "\n",
    "def loss_function(x_n, x_n_recon, r_n, r_n_recon, mu, log_var):\n",
    "    # Ensure x_n and r_n are unsqueezed if needed (depends on data shape handling in other parts of your code)\n",
    "    x_n = torch.unsqueeze(x_n, dim=0) if len(x_n.shape) < 3 else x_n\n",
    "    r_n = torch.unsqueeze(r_n, dim=0) if len(r_n.shape) < 3 else r_n\n",
    "\n",
    "    # Calculate the mean squared error, normalized by the number of elements (H*W)\n",
    "    recon_loss_x = F.mse_loss(x_n_recon, x_n, reduction='mean') / (H * W)\n",
    "    recon_loss_r = F.mse_loss(r_n_recon, r_n, reduction='mean')\n",
    "\n",
    "    # Calculate the Kullback-Leibler divergence\n",
    "    kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "\n",
    "    # Combine the losses with the scaling factors\n",
    "    total_loss = recon_loss_x + alpha * recon_loss_r + beta * kl_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "param_grid = {\n",
    "    'hidden_size': [50, 100, 200, 300, 400],\n",
    "    'latent_size': [2, 5, 10, 20, 30],\n",
    "    'learning_rate': [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "    'alpha': [0.1, 0.5, 1.0, 2.0, 5.0],\n",
    "    'beta': [1e-6, 1e-5, 1e-4, 1e-3, 1e-2],\n",
    "    'batch_size': [16, 32, 64, 128],\n",
    "    'num_epochs': [100, 200, 300, 400, 500]\n",
    "}\n",
    "\n",
    "# Generate all possible combinations of hyperparameters\n",
    "hyperparameter_combinations = ParameterGrid(param_grid)\n",
    "\n",
    "# Initialize variables to store the best hyperparameters and validation loss\n",
    "best_hyperparameters = None\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 5\n",
    "\n",
    "# Create a KFold object for cross-validation\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Iterate over each combination of hyperparameters\n",
    "for params in hyperparameter_combinations:\n",
    "    hidden_size = params['hidden_size']\n",
    "    latent_size = params['latent_size']\n",
    "    learning_rate = params['learning_rate']\n",
    "    alpha = params['alpha']\n",
    "    beta = params['beta']\n",
    "    batch_size = params['batch_size']\n",
    "    num_epochs = params['num_epochs']\n",
    "\n",
    "    # Initialize variables to store the total validation loss across all folds\n",
    "    total_val_loss = 0.0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold, (train_indices, val_indices) in enumerate(kfold.split(X_train_reshaped)):\n",
    "        print(f\"Fold {fold + 1}/{num_folds}\")\n",
    "\n",
    "        # Create data subsets for the current fold\n",
    "        train_subset = TensorDataset(torch.Tensor(X_train_reshaped[train_indices]), torch.Tensor(y_train_reshaped[train_indices]))\n",
    "        val_subset = TensorDataset(torch.Tensor(X_train_reshaped[val_indices]), torch.Tensor(y_train_reshaped[val_indices]))\n",
    "\n",
    "        # Create data loaders for the current fold\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Create the model with the current hyperparameters\n",
    "        model = CVAE(input_size, hidden_size, latent_size, context_size, input_size, num_surfaces)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            for batch in train_loader:\n",
    "                x, y = batch\n",
    "                batch_size = x.shape[0]  # batch_size, context_length, num_surfaces, H, W = x.shape\n",
    "\n",
    "                # Generate a random day t to split the sequence into context and future\n",
    "                t = batch_size - num_surfaces - 1\n",
    "\n",
    "                x_c, x_n = x[:t, :], x[t:, :]\n",
    "                y_c, y_n = y[:t, :], y[t:, :]\n",
    "                r_n = y_n[:, :, 0]\n",
    "\n",
    "                x_n_recon, r_n_recon, mu, log_var = model(x, y, x_c, y_c)\n",
    "\n",
    "                # Compute the loss\n",
    "                loss = loss_function(x_n[0], x_n_recon, r_n[0], r_n_recon, mu, log_var)\n",
    "\n",
    "                # Backward pass and optimization\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "\n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    x, y = batch\n",
    "                    batch_size = x.shape[0]  # Number of days in the sequence\n",
    "\n",
    "                    # Generate a random day t to split the sequence into context and future\n",
    "                    t = batch_size - num_surfaces - 1\n",
    "\n",
    "                    x_c, x_n = x[:t, :], x[t:, :]\n",
    "                    y_c, y_n = y[:t, :], y[t:, :]\n",
    "\n",
    "                    # Extract the log return feature from y_n\n",
    "                    r_n = y_n[:, :, 0]\n",
    "\n",
    "                    x_n_recon, r_n_recon, mu, log_var = model(x, y, x_c, y_c)\n",
    "\n",
    "                    # Compute the loss\n",
    "                    loss = loss_function(x_n[0], x_n_recon, r_n[0], r_n_recon, mu, log_var)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "            # Print the losses for each epoch\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}\")\n",
    "\n",
    "        # Accumulate the validation loss for the current fold\n",
    "        total_val_loss += val_loss\n",
    "\n",
    "    # Calculate the average validation loss across all folds\n",
    "    avg_val_loss = total_val_loss / num_folds\n",
    "\n",
    "    # Check if the current hyperparameters yield a better validation loss\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_hyperparameters = params\n",
    "\n",
    "# Print the best hyperparameters and validation loss\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_hyperparameters)\n",
    "print(f\"Best Validation Loss: {best_val_loss:.4f}\")\n",
    "\n",
    "# Train the final model with the best hyperparameters on the entire training set\n",
    "best_model = CVAE(input_size, best_hyperparameters['hidden_size'], best_hyperparameters['latent_size'],\n",
    "                  context_size, input_size, num_surfaces)\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=best_hyperparameters['learning_rate'])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=best_hyperparameters['batch_size'], shuffle=True)\n",
    "\n",
    "for epoch in range(best_hyperparameters['num_epochs']):\n",
    "    # Training\n",
    "    best_model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        batch_size = x.shape[0]  # batch_size, context_length, num_surfaces, H, W = x.shape\n",
    "\n",
    "        # Generate a random day t to split the sequence into context and future\n",
    "        t = batch_size - num_surfaces - 1\n",
    "\n",
    "        x_c, x_n = x[:t, :], x[t:, :]\n",
    "        y_c, y_n = y[:t, :], y[t:, :]\n",
    "        r_n = y_n[:, :, 0]\n",
    "\n",
    "        x_n_recon, r_n_recon, mu, log_var = best_model(x, y, x_c, y_c)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = loss_function(x_n[0], x_n_recon, r_n[0], r_n_recon, mu, log_var)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Print the training loss for each epoch\n",
    "    print(f\"Epoch [{epoch+1}/{best_hyperparameters['num_epochs']}], Train Loss: {train_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Evaluate the final model on the test set\n",
    "best_model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x, y = batch\n",
    "        batch_size = x.shape[0]  # Number of days in the sequence\n",
    "\n",
    "        # Generate a random day t to split the sequence into context and future\n",
    "        t = batch_size - num_surfaces - 1\n",
    "\n",
    "        x_c, x_n = x[:t, :], x[t:, :]\n",
    "        y_c, y_n = y[:t, :], y[t:, :]\n",
    "\n",
    "        # Extract the log return feature from y_n\n",
    "        r_n = y_n[:, :, 0]\n",
    "\n",
    "        x_n_recon, r_n_recon, mu, log_var = best_model(x, y, x_c, y_c)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = loss_function(x_n[0], x_n_recon, r_n[0], r_n_recon, mu, log_var)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "print(f\"Test Loss: {test_loss/len(test_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77e94949-b7df-4e6c-8b89-a52f82092429",
   "metadata": {},
   "outputs": [],
   "source": [
    "####IV SURFACE 1 FORECAST ASSESSMENT\n",
    "\n",
    "import time\n",
    "from scipy.optimize import brentq\n",
    "from scipy.stats import norm\n",
    "\n",
    "moneyness_levels = [0.7, 0.85, 1, 1.15, 1.3]\n",
    "ttms = [1, 3, 6, 12, 24]\n",
    "\n",
    "def black_scholes_call(S, K, T, r, sigma):\n",
    "    d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))\n",
    "    d2 = d1 - sigma * np.sqrt(T)\n",
    "    return S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)\n",
    "    \n",
    "def find_iv(market_price, S, K, T, r):\n",
    "    def objective(sigma): return market_price - black_scholes_call(S, K, T, r, sigma)\n",
    "    try:\n",
    "        return brentq(objective, 1e-6, 3.0, xtol=1e-6)\n",
    "    except ValueError:\n",
    "        return np.nan  # or any other default value\n",
    "\n",
    "def find_closest_moneyness_range_and_ttm(underlying_price, strike_price, T):\n",
    "    moneyness = underlying_price / strike_price\n",
    "    closest_range = None\n",
    "    min_diff = float('inf')\n",
    "    moneyness_index = 99\n",
    "    ttm_index = 99\n",
    "    \n",
    "    counter = 0\n",
    "    for level in moneyness_levels:\n",
    "        diff = abs(moneyness - level)\n",
    "        if diff < min_diff:\n",
    "            min_diff = diff\n",
    "            closest_range = level\n",
    "            moneyness_index = counter\n",
    "    counter = counter + 1\n",
    "\n",
    "    counter=0\n",
    "    for ttm in ttms:\n",
    "        if T == ttm:\n",
    "            ttm_index = counter\n",
    "        counter = counter + 1\n",
    "\n",
    "    return closest_range, min_diff, moneyness_index, ttm_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90899fac-f15f-4ddc-8a1e-aeb124ac3962",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "CVAE(\n",
      "  (encoder): Encoder(\n",
      "    (cnn): CNN(\n",
      "      (conv1): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (fc): Linear(in_features=125, out_features=5, bias=True)\n",
      "    )\n",
      "    (mlp): Identity()\n",
      "    (lstm): LSTM(8, 100, num_layers=2, batch_first=True, dropout=0.2)\n",
      "    (linear_mu): Linear(in_features=100, out_features=5, bias=True)\n",
      "    (linear_sigma): Linear(in_features=100, out_features=5, bias=True)\n",
      "  )\n",
      "  (context_encoder): ContextEncoder(\n",
      "    (cnn): CNN(\n",
      "      (conv1): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (fc): Linear(in_features=125, out_features=5, bias=True)\n",
      "    )\n",
      "    (mlp): Identity()\n",
      "    (lstm): LSTM(8, 100, num_layers=2, batch_first=True, dropout=0.2)\n",
      "    (linear): Linear(in_features=100, out_features=5, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (lstm): LSTM(10, 100, num_layers=2, batch_first=True, dropout=0.2)\n",
      "    (tcnn): TCNN(\n",
      "      (fc1): Linear(in_features=100, out_features=128, bias=True)\n",
      "      (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (fc3): Linear(in_features=64, out_features=25, bias=True)\n",
      "    )\n",
      "    (mlp): Linear(in_features=100, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor(-0.0598, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0027, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0598, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0027, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0598, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0027, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sl/_44jn7jx03b17y35qvlp17sr0000gn/T/ipykernel_25241/3974122423.py:20: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x = iv_surfaces.drop(['Log Return', 'Skew', 'Slope'], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0592, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0361, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0633, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0592, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0361, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0633, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0592, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0361, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0633, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0597, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0029, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0369, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0597, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0029, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0369, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0597, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0029, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0369, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0592, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0364, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0592, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0364, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0592, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0364, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0363, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0363, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0363, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0598, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0028, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0369, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0598, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0028, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0369, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0598, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0028, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0369, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0595, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0024, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0370, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0595, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0024, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0370, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0595, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0024, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0370, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0594, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0364, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0594, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0364, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0594, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0364, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0027, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0639, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0027, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0639, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0027, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0639, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0586, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0010, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0360, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0586, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0010, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0360, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0586, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0010, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0360, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0598, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0022, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0369, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0598, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0022, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0369, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0598, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0022, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0369, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0605, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0026, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0370, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0022, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0605, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0026, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0370, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0022, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0605, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0026, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0370, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0022, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0594, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0370, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0641, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0594, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0370, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0641, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0594, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0370, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0641, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0589, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0023, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0368, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0642, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0589, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0023, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0368, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0642, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0589, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0023, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0368, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0642, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0596, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0024, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0596, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0024, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0596, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0024, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0603, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0027, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0369, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0603, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0027, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0369, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0603, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0027, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0369, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0009, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0363, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0009, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0363, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0009, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0363, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0592, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0365, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0592, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0365, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0592, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0365, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0590, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0007, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0362, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0590, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0007, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0362, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0590, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0007, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0362, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0359, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0631, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0359, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0631, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0359, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0631, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0360, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0632, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0360, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0632, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0360, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0632, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0597, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0025, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0597, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0025, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0597, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0025, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0599, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0028, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0368, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0599, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0028, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0368, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0599, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0028, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0368, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0012, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0364, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0012, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0364, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0012, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0364, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0588, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0368, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0643, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0588, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0368, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0643, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0588, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0368, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0643, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0592, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0012, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0360, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0633, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0012, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0592, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0012, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0360, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0633, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0012, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0592, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0012, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0360, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0633, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0012, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0027, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0027, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0027, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0588, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0362, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0588, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0362, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0588, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0362, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0595, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0024, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0368, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0595, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0024, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0368, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0595, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0024, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0368, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0589, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0023, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0363, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0589, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0023, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0363, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0589, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0023, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0363, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0641, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0641, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0641, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0588, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0009, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0359, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0634, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0588, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0009, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0359, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0634, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0588, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0009, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0359, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0634, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0603, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0033, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0603, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0033, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0603, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0033, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0592, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0009, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0356, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0630, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0592, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0009, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0356, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0630, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0592, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0009, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0356, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0630, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0594, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0025, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0594, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0025, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0594, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0025, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0600, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0025, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0374, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0643, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0600, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0025, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0374, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0643, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0600, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0025, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0374, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0643, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0594, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0026, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0363, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0633, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0594, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0026, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0363, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0633, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0594, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0026, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0363, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0633, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0024, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0369, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0641, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0024, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0369, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0641, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0024, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0369, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0641, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0364, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0364, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0364, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0588, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0362, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0588, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0362, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0588, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0362, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0596, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0021, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0596, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0021, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0596, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0021, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0588, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0361, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0588, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0361, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0588, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0361, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0025, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0364, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0025, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0364, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0025, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0364, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0590, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0590, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0590, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0596, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0024, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0368, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0596, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0024, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0368, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0596, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0024, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0368, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0598, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0368, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0598, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0368, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0598, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0368, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0604, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0041, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0374, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0643, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0604, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0041, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0374, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0643, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0604, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0041, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0374, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0643, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0603, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0028, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0372, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0603, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0028, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0372, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0603, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0028, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0372, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0596, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0025, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0596, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0025, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0596, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0025, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0595, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0595, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0595, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0606, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0039, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0375, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0642, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0022, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0606, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0039, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0375, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0642, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0022, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0606, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0039, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0375, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0642, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0022, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0369, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0641, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0369, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0641, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0369, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0641, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0603, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0036, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0374, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0603, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0036, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0374, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0603, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0036, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0374, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0599, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0021, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0599, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0021, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0599, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0021, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0592, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0364, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0592, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0364, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0592, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0364, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0595, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0023, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0368, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0639, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0595, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0023, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0368, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0639, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0595, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0023, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0368, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0639, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0596, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0363, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0632, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0596, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0363, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0632, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0596, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0363, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0632, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0594, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0362, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0633, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0594, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0362, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0633, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0594, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0362, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0633, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0365, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0365, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0365, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0007, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0361, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0634, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0007, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0361, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0634, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0007, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0361, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0634, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0025, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0368, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0025, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0368, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0025, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0368, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0604, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0030, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0369, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0021, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0604, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0030, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0369, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0021, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0604, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0030, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0369, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0021, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0601, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0027, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0634, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0601, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0027, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0634, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0601, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0027, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0634, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0361, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0634, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0361, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0634, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0361, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0634, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0594, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0363, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0634, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0594, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0363, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0634, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0594, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0363, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0634, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0596, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0035, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0596, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0035, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0596, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0035, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0587, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0363, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0587, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0363, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0587, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0363, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0594, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0029, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0594, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0029, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0594, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0029, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0592, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0028, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0592, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0028, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0592, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0028, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0598, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0032, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0370, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0598, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0032, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0370, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0598, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0032, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0370, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0597, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0030, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0369, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0597, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0030, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0369, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0597, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0030, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0369, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0600, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0022, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0600, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0022, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0600, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0022, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0604, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0024, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0365, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0631, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0604, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0024, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0365, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0631, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0604, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0024, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0365, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0631, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0603, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0031, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0372, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0603, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0031, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0372, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0603, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0031, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0372, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0588, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0362, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0588, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0362, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0588, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0362, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0595, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0595, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0595, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0592, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0639, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0592, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0639, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0592, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0639, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0596, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0023, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0365, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0596, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0023, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0365, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0596, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0023, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0365, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0585, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0359, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0585, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0359, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0585, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0359, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0590, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0364, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0590, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0364, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0590, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0364, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0595, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0026, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0595, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0026, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0595, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0026, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0007, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0362, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0007, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0362, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0007, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0362, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0023, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0365, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0023, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0365, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0593, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0023, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0365, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0365, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0365, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0365, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0586, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0004, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0362, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0586, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0004, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0362, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0586, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0004, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0362, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0594, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0028, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0365, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0594, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0028, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0365, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0594, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0028, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0365, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0600, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0365, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0633, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0600, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0365, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0633, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0600, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0365, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0633, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0599, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0028, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0370, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0639, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0599, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0028, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0370, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0639, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0599, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0028, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0370, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0639, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0599, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0024, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0370, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0639, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0599, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0024, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0370, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0639, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0599, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0024, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0370, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0639, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0590, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0364, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0590, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0364, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0590, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0364, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0638, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0594, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0594, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0594, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0367, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0636, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0598, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0364, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0021, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0598, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0364, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0021, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0598, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0014, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0364, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0635, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0021, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0639, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0639, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0591, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0013, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0639, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0015, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0596, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0370, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0596, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0370, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0596, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0020, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0370, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0640, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0599, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0030, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0369, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0639, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0599, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0030, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0369, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0639, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0599, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0030, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0369, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0639, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0016, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0596, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0596, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0596, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0018, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0366, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0637, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0019, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0598, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0021, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0371, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0639, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0598, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0021, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0371, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0639, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0598, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0021, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0371, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0639, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.0017, grad_fn=<SelectBackward0>)\n",
      "1423 options bought\n",
      "Total profit: -2203.8689457078885\n",
      "Profit per trade: -1.5487483806801747\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model state dictionary\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "print(\"Model loaded successfully.\")\n",
    "# Set the model to evaluation mode\n",
    "print(model.eval())\n",
    "    \n",
    "#underlying params for black scholes\n",
    "r = 0.05 #risk_free_rate\n",
    "volatility = 0.04 #long term volatility\n",
    "time_to_maturity = 1.0\n",
    "\n",
    "file_path = 'option_prices_timeseries.csv'\n",
    "options = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "file_path = 'combined_iv_data_new.csv'\n",
    "iv_surfaces = pd.read_csv(file_path, header=[0, 1], index_col=0)\n",
    "\n",
    "y = iv_surfaces[['Log Return', 'Skew', 'Slope']]\n",
    "\n",
    "x = iv_surfaces.drop(['Log Return', 'Skew', 'Slope'], axis=1)\n",
    "\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "y = scaler.fit_transform(y)\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "x_reshaped = x.reshape(x.shape[0],  H, W)\n",
    "\n",
    "y_reshaped = y.reshape(y.shape[0], 1, extra_features_size)\n",
    "\n",
    "iv_surfaces_tensor = TensorDataset(torch.Tensor(x_reshaped ), torch.Tensor(y_reshaped))\n",
    "\n",
    "x = [x[0] for x in iv_surfaces_tensor]\n",
    "y = [x[1] for x in iv_surfaces_tensor]\n",
    "\n",
    "bought_options = []\n",
    "\n",
    "#expiration_date =  50\n",
    "#asset_price_at_expiration = options.loc[expiration_date][\"Asset Price\"].iloc[0]\n",
    "#print(asset_price_at_expiration)\n",
    "\n",
    "\n",
    "for i in range(32, 132): ##start from 32 so i can have enough context\n",
    "    #print('hi')\n",
    "    options_t = options.loc[i]\n",
    "    x_c = x[i-31:i]\n",
    "    y_c = y[i-31:i]\n",
    "\n",
    "    x_c = torch.stack(x_c)\n",
    "    y_c = torch.stack(y_c)\n",
    "    x_n, r_n = model.generate(x_c, y_c, 1) ##predict 1 unit in the future\n",
    "\n",
    "\n",
    "    for _, selected_row in options_t.iterrows():\n",
    "        #print(selected_row)\n",
    "        S = selected_row[\"Asset Price\"] \n",
    "        K = selected_row[\"Strike\"]\n",
    "        T = selected_row[\"Time to Maturity (Months)\"] ##TTM in months\n",
    "        market_price = selected_row[\"Call Price\"]\n",
    "        iv = find_iv(market_price, S, K, T / 12, r)\n",
    "        if iv == np.nan:\n",
    "            continue\n",
    "\n",
    "        #print(iv)\n",
    "        level, diff, moneyness_index, ttm_index = find_closest_moneyness_range_and_ttm(S, K, int(T))\n",
    "        if moneyness_index == 99:\n",
    "            continue\n",
    "\n",
    "       # print(moneyness_index)\n",
    "        #print(\"I am here\")\n",
    "        if diff < 0.05: ##close to actual moneyness level compare ivs with ttm and moneyness on forecast - will be underpriced\n",
    "           # print(T)\n",
    "            forecast_iv = x_n[0][0][moneyness_index][ttm_index]\n",
    "            print(forecast_iv)\n",
    "            #print(forecast_iv)\n",
    "            #print(f\"black scholes iv: {abs(iv)}\")\n",
    "            #print(f\"The forecast iv: {forecast_iv}\")\n",
    "            if abs(forecast_iv) < abs(iv):\n",
    "                bought_options.append((i, S, K, T, market_price)) \n",
    "                #print('buy\\n\\n')\n",
    "\n",
    "total_profit = 0\n",
    "\n",
    "for option in bought_options:\n",
    "    buy_date, S, K, T, market_price = option\n",
    "    expiration_date = buy_date + int(T) * 30 #months\n",
    "    if expiration_date < 5886:\n",
    "        asset_price_at_expiration = options.loc[expiration_date][\"Asset Price\"].iloc[0]\n",
    "            # If asset_price_at_expiration is a scalar value, calculate profit as before\n",
    "        if asset_price_at_expiration > K:\n",
    "            profit = asset_price_at_expiration - K - market_price\n",
    "        else:\n",
    "            profit = -market_price \n",
    "            total_profit += profit\n",
    "            \n",
    "print(f\"{len(bought_options)} options bought\")\n",
    "print(f\"Total profit: {total_profit}\")\n",
    "print(f\"Profit per trade: {total_profit / len(bought_options)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2fc86360-0e88-4d30-afd3-81b0c4023150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "options bought\n",
      "2208 options bought\n",
      "Total profit: -2925.015882750329\n",
      "Profit per trade: -1.324735454144171\n"
     ]
    }
   ],
   "source": [
    "file_path = 'option_prices_timeseries.csv'\n",
    "options = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "#underlying params for black scholes\n",
    "r = 0.05 #risk_free_rate\n",
    "volatility = 0.04 #long term volatility\n",
    "time_to_maturity = 1.0\n",
    "\n",
    "##Black scholes  ASSESSMENT\n",
    "longterm_volatility = 0.04 #long term volatility\n",
    "\n",
    "bought_options = []\n",
    "for i in range(32, 132): ##start from 32 so i can have enough context\n",
    "    #print('hi')\n",
    "    options_t = options.loc[i]\n",
    "    for _, selected_row in options_t.iterrows():\n",
    "        #print(selected_row)\n",
    "        S = selected_row[\"Asset Price\"] \n",
    "        K = selected_row[\"Strike\"]\n",
    "        T = selected_row[\"Time to Maturity (Months)\"] ##TTM in months\n",
    "        market_price = selected_row[\"Call Price\"]\n",
    "        iv = find_iv(market_price, S, K, T / 12, r)\n",
    "        if iv == np.nan:\n",
    "            continue\n",
    "\n",
    "        if abs(longterm_volatility) < abs(iv):\n",
    "            bought_options.append((i, S, K, T, market_price)) \n",
    "            #print('buy\\n\\n')\n",
    "\n",
    "total_profit = 0\n",
    "\n",
    "print('options bought')\n",
    "for option in bought_options:\n",
    "    buy_date, S, K, T, market_price = option\n",
    "    expiration_date = buy_date + int(T) * 30 #months\n",
    "    if expiration_date < 5886:\n",
    "        asset_price_at_expiration = options.loc[expiration_date][\"Asset Price\"].iloc[0]\n",
    "            # If asset_price_at_expiration is a scalar value, calculate profit as before\n",
    "        if asset_price_at_expiration > K:\n",
    "            profit = asset_price_at_expiration - K - market_price\n",
    "        else:\n",
    "            profit = -market_price \n",
    "            total_profit += profit\n",
    "\n",
    "print(f\"{len(bought_options)} options bought\")\n",
    "print(f\"Total profit: {total_profit}\")\n",
    "print(f\"Profit per trade: {total_profit / len(bought_options)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e01682a-2b58-4ea5-a9d6-d7a9ac395880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "options bought\n",
      "1279 options bought\n",
      "Total profit: -1529.4891569069061\n",
      "Profit per trade: -1.195847659817753\n"
     ]
    }
   ],
   "source": [
    "file_path = 'option_prices_timeseries.csv'\n",
    "options = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "##Buy Random  ASSESSMENT\n",
    "longterm_volatility = 0.04 #long term volatility\n",
    "#underlying params for black scholes\n",
    "r = 0.05 #risk_free_rate\n",
    "volatility = 0.04 #long term volatility\n",
    "time_to_maturity = 1.0\n",
    "\n",
    "bought_options = []\n",
    "for i in range(32, 132): ##start from 32 so i can have enough context\n",
    "    #print('hi')\n",
    "    options_t = options.loc[i]\n",
    "    for _, selected_row in options_t.iterrows():\n",
    "        #print(selected_row)\n",
    "        S = selected_row[\"Asset Price\"] \n",
    "        K = selected_row[\"Strike\"]\n",
    "        T = selected_row[\"Time to Maturity (Months)\"] ##TTM in months\n",
    "        market_price = selected_row[\"Call Price\"]\n",
    "        iv = find_iv(market_price, S, K, T / 12, r)\n",
    "\n",
    "        import random\n",
    "\n",
    "        # Generates True or False with equal probability\n",
    "        result = random.choice([True, False])\n",
    "        #print(result)\n",
    "\n",
    "        if result:\n",
    "            bought_options.append((i, S, K, T, market_price)) \n",
    "            #print('buy\\n\\n')\n",
    "\n",
    "total_profit = 0\n",
    "\n",
    "print('options bought')\n",
    "for option in bought_options:\n",
    "    buy_date, S, K, T, market_price = option\n",
    "    expiration_date = buy_date + int(T) * 30 #months\n",
    "    if expiration_date < 5886:\n",
    "        asset_price_at_expiration = options.loc[expiration_date][\"Asset Price\"].iloc[0]\n",
    "            # If asset_price_at_expiration is a scalar value, calculate profit as before\n",
    "        if asset_price_at_expiration > K:\n",
    "            profit = asset_price_at_expiration - K - market_price\n",
    "        else:\n",
    "            profit = -market_price \n",
    "            total_profit += profit\n",
    "\n",
    "print(f\"{len(bought_options)} options bought\")\n",
    "print(f\"Total profit: {total_profit}\")\n",
    "print(f\"Profit per trade: {total_profit / len(bought_options)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f46c166-d2bf-43bc-85c8-831faa360fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "CVAE(\n",
      "  (encoder): Encoder(\n",
      "    (cnn): CNN(\n",
      "      (conv1): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (fc): Linear(in_features=125, out_features=5, bias=True)\n",
      "    )\n",
      "    (mlp): Identity()\n",
      "    (lstm): LSTM(8, 100, num_layers=2, batch_first=True, dropout=0.2)\n",
      "    (linear_mu): Linear(in_features=100, out_features=5, bias=True)\n",
      "    (linear_sigma): Linear(in_features=100, out_features=5, bias=True)\n",
      "  )\n",
      "  (context_encoder): ContextEncoder(\n",
      "    (cnn): CNN(\n",
      "      (conv1): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (fc): Linear(in_features=125, out_features=5, bias=True)\n",
      "    )\n",
      "    (mlp): Identity()\n",
      "    (lstm): LSTM(8, 100, num_layers=2, batch_first=True, dropout=0.2)\n",
      "    (linear): Linear(in_features=100, out_features=5, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (lstm): LSTM(10, 100, num_layers=2, batch_first=True, dropout=0.2)\n",
      "    (tcnn): TCNN(\n",
      "      (fc1): Linear(in_features=100, out_features=128, bias=True)\n",
      "      (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (fc3): Linear(in_features=64, out_features=25, bias=True)\n",
      "    )\n",
      "    (mlp): Linear(in_features=100, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sl/_44jn7jx03b17y35qvlp17sr0000gn/T/ipykernel_25241/3846021429.py:53: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x = iv_surfaces.drop(['Log Return', 'Skew', 'Slope'], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "options bought\n",
      "300 options bought\n",
      "Total profit: -939.9564074235823\n",
      "Profit per trade: -3.1331880247452744\n"
     ]
    }
   ],
   "source": [
    "###In this generate empircal expected value/profit\n",
    "def predict_profit(x_c, y_c, t, N, S, K, market_price):\n",
    "    total_profit = 0\n",
    "    num_iterations = 0\n",
    "\n",
    "    for i in range(1, N):\n",
    "        x_n, r_n = model.generate(x_c, y_c, t)  # predict t units in the future\n",
    "\n",
    "        # Calculate the asset price at expiration using the generated log returns\n",
    "        asset_price_at_expiration = S\n",
    "       # print(r_n)\n",
    "        for j in range(t):\n",
    "            asset_price_at_expiration *= np.exp(r_n[j].detach().numpy())  # Assuming r_n has shape (t, 1, 1)\n",
    "\n",
    "        # Calculate the profit for the option\n",
    "        if asset_price_at_expiration > K:\n",
    "            profit = asset_price_at_expiration - K - market_price\n",
    "        else:\n",
    "            profit = -market_price\n",
    "\n",
    "        total_profit += profit\n",
    "        num_iterations += 1\n",
    "\n",
    "    # Calculate the average profit\n",
    "    if num_iterations > 0:\n",
    "        average_profit = total_profit / num_iterations\n",
    "    else:\n",
    "        average_profit = 0\n",
    "\n",
    "    return average_profit\n",
    "    \n",
    "\n",
    "    \n",
    "# Load the saved model state dictionary\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "print(\"Model loaded successfully.\")\n",
    "# Set the model to evaluation mode\n",
    "print(model.eval())\n",
    "    \n",
    "#underlying params for black scholes\n",
    "r = 0.05 #risk_free_rate\n",
    "volatility = 0.04 #long term volatility\n",
    "time_to_maturity = 1.0\n",
    "\n",
    "file_path = 'option_prices_timeseries.csv'\n",
    "options = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "file_path = 'combined_iv_data_new.csv'\n",
    "iv_surfaces = pd.read_csv(file_path, header=[0, 1], index_col=0)\n",
    "\n",
    "y = iv_surfaces[['Log Return', 'Skew', 'Slope']]\n",
    "\n",
    "x = iv_surfaces.drop(['Log Return', 'Skew', 'Slope'], axis=1)\n",
    "\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "y = scaler.fit_transform(y)\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "x_reshaped = x.reshape(x.shape[0],  H, W)\n",
    "\n",
    "y_reshaped = y.reshape(y.shape[0], 1, extra_features_size)\n",
    "\n",
    "iv_surfaces_tensor = TensorDataset(torch.Tensor(x_reshaped ), torch.Tensor(y_reshaped))\n",
    "\n",
    "x = [x[0] for x in iv_surfaces_tensor]\n",
    "y = [x[1] for x in iv_surfaces_tensor]\n",
    "\n",
    "bought_options = []\n",
    "\n",
    "\n",
    "N = 10 ##outcomes to generate\n",
    "\n",
    "\n",
    "##only do ttm of 1\n",
    "for i in range(32, 132): ##start from 32 so i can have enough context\n",
    "    x_hat = []\n",
    "    r_hat = []\n",
    "\n",
    "    \n",
    "    options_t = options.loc[i]\n",
    "    x_c = x[i-31:i]\n",
    "    y_c = y[i-31:i]\n",
    "\n",
    "    x_c = torch.stack(x_c)\n",
    "    y_c = torch.stack(y_c)\n",
    "\n",
    "    for _, selected_row in options_t.iterrows():\n",
    "        T = selected_row[\"Time to Maturity (Months)\"] ##TTM in months\n",
    "        if int(T) != 24:\n",
    "            continue\n",
    "        S = selected_row[\"Asset Price\"] \n",
    "        K = selected_row[\"Strike\"]\n",
    "        market_price = selected_row[\"Call Price\"]\n",
    "        iv = find_iv(market_price, S, K, T / 12, r)\n",
    "\n",
    "        empircal_profit = predict_profit(x_c, y_c, int(T), N, S, K, market_price)\n",
    "        if iv == np.nan:\n",
    "            continue\n",
    "\n",
    "        level, diff, moneyness_index, ttm_index = find_closest_moneyness_range_and_ttm(S, K, int(T))\n",
    "        if moneyness_index == 99:\n",
    "            continue\n",
    "\n",
    "        if diff < 0.05: ##close to actual moneyness level compare ivs with ttm and moneyness on forecast - will be underpriced\n",
    "            if empircal_profit > 1: ###if profit is above a threshold here for room \n",
    "                bought_options.append((i, S, K, T, market_price)) \n",
    "\n",
    "    #print(i)\n",
    "\n",
    "total_profit = 0\n",
    "\n",
    "print('options bought')\n",
    "for option in bought_options:\n",
    "    buy_date, S, K, T, market_price = option\n",
    "    expiration_date = buy_date + int(T) * 30 #months\n",
    "    if expiration_date < 5886:\n",
    "        asset_price_at_expiration = options.loc[expiration_date][\"Asset Price\"].iloc[0]\n",
    "            # If asset_price_at_expiration is a scalar value, calculate profit as before\n",
    "        if asset_price_at_expiration > K:\n",
    "            profit = asset_price_at_expiration - K - market_price\n",
    "        else:\n",
    "            profit = -market_price \n",
    "            total_profit += profit\n",
    "\n",
    "print(f\"{len(bought_options)} options bought\")\n",
    "print(f\"Total profit: {total_profit}\")\n",
    "print(f\"Profit per trade: {total_profit / len(bought_options)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc61adc6-8e8a-481c-b36e-de528b58b3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "CVAE(\n",
      "  (encoder): Encoder(\n",
      "    (cnn): CNN(\n",
      "      (conv1): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (fc): Linear(in_features=125, out_features=5, bias=True)\n",
      "    )\n",
      "    (mlp): Identity()\n",
      "    (lstm): LSTM(8, 100, num_layers=2, batch_first=True, dropout=0.2)\n",
      "    (linear_mu): Linear(in_features=100, out_features=5, bias=True)\n",
      "    (linear_sigma): Linear(in_features=100, out_features=5, bias=True)\n",
      "  )\n",
      "  (context_encoder): ContextEncoder(\n",
      "    (cnn): CNN(\n",
      "      (conv1): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (fc): Linear(in_features=125, out_features=5, bias=True)\n",
      "    )\n",
      "    (mlp): Identity()\n",
      "    (lstm): LSTM(8, 100, num_layers=2, batch_first=True, dropout=0.2)\n",
      "    (linear): Linear(in_features=100, out_features=5, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (lstm): LSTM(10, 100, num_layers=2, batch_first=True, dropout=0.2)\n",
      "    (tcnn): TCNN(\n",
      "      (fc1): Linear(in_features=100, out_features=128, bias=True)\n",
      "      (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (fc3): Linear(in_features=64, out_features=25, bias=True)\n",
      "    )\n",
      "    (mlp): Linear(in_features=100, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sl/_44jn7jx03b17y35qvlp17sr0000gn/T/ipykernel_28197/502974876.py:48: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x = iv_surfaces.drop(['Log Return', 'Skew', 'Slope'], axis=1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 104\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m moneyness_index \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m99\u001b[39m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m forecast_iv \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_iv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmoneyness_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mttm_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m diff \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.05\u001b[39m: \u001b[38;5;66;03m##close to actual moneyness level compare ivs with ttm and moneyness on forecast - will be underpriced\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m#print('I AM HERE')\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(forecast_iv) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mabs\u001b[39m(iv): \u001b[38;5;66;03m###if profit is above a threshold here for room \u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m, in \u001b[0;36mpredict_iv\u001b[0;34m(x_c, y_c, t, N, moneyness_index, ttm_index)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m##by the WLLN if our model is accurate it should converge to the true average profitability making a positive ev trading strategy\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, N):\n\u001b[0;32m---> 10\u001b[0m     x_n, r_n \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# predict t units in the future\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     predicted_iv_surface \u001b[38;5;241m=\u001b[39m x_n[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m#print(f\"x_n: {x_n}\")\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m#print(f\"predicted iv surface: {predicted_iv_surface}\")\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m#print(predicted_iv_surface)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 30\u001b[0m, in \u001b[0;36mCVAE.generate\u001b[0;34m(self, x_c, y_c, ttm)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, ttm):\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# reasing z and context\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)]), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 30\u001b[0m     zeta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_c\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     x_n, r_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(z, zeta)\n\u001b[1;32m     32\u001b[0m     x_hat\u001b[38;5;241m.\u001b[39mappend(x_n)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 47\u001b[0m, in \u001b[0;36mContextEncoder.forward\u001b[0;34m(self, x_c, y_c)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#print(f\"x_encoded size = {x_encoded.shape} ||y_encoded size = {y_encoded.shape}\")\u001b[39;00m\n\u001b[1;32m     46\u001b[0m encoded \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x_encoded, y_encoded), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m _, (hidden, _) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m hidden \u001b[38;5;241m=\u001b[39m hidden[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Take the last hidden state\u001b[39;00m\n\u001b[1;32m     49\u001b[0m zeta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(hidden)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/rnn.py:878\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    875\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 878\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    882\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###In this generate empircal expected value/profit\n",
    "def predict_iv(x_c, y_c, t, N, moneyness_index, ttm_index):\n",
    "    total_profit = 0\n",
    "    num_iterations = 0\n",
    "\n",
    "    sum_iv = 0\n",
    "    num_iv = 0\n",
    "    ##by the WLLN if our model is accurate it should converge to the true average profitability making a positive ev trading strategy\n",
    "    for i in range(1, N):\n",
    "        x_n, r_n = model.generate(x_c, y_c, t)  # predict t units in the future\n",
    "        predicted_iv_surface = x_n[0][0]\n",
    "        #print(f\"x_n: {x_n}\")\n",
    "        #print(f\"predicted iv surface: {predicted_iv_surface}\")\n",
    "        #print(predicted_iv_surface)\n",
    "        iv = predicted_iv_surface[ttm_index][moneyness_index]\n",
    "        #print(iv)\n",
    "        sum_iv = sum_iv + abs(iv)\n",
    "        num_iv = num_iv + 1\n",
    "        #print('here')\n",
    "\n",
    "    forecast_iv = (sum_iv / num_iv) #num_iv just N no\n",
    "\n",
    "    #print(f\"forecast iv: {forecast_iv}\")\n",
    "\n",
    "    return forecast_iv \n",
    "    \n",
    "\n",
    "    \n",
    "# Load the saved model state dictionary\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "print(\"Model loaded successfully.\")\n",
    "# Set the model to evaluation mode\n",
    "print(model.eval())\n",
    "    \n",
    "#underlying params for black scholes\n",
    "r = 0.05 #risk_free_rate\n",
    "volatility = 0.04 #long term volatility\n",
    "time_to_maturity = 1.0\n",
    "\n",
    "file_path = 'option_prices_timeseries.csv'\n",
    "options = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "file_path = 'combined_iv_data_new.csv'\n",
    "iv_surfaces = pd.read_csv(file_path, header=[0, 1], index_col=0)\n",
    "\n",
    "y = iv_surfaces[['Log Return', 'Skew', 'Slope']]\n",
    "\n",
    "x = iv_surfaces.drop(['Log Return', 'Skew', 'Slope'], axis=1)\n",
    "\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "y = scaler.fit_transform(y)\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "x_reshaped = x.reshape(x.shape[0],  H, W)\n",
    "\n",
    "y_reshaped = y.reshape(y.shape[0], 1, extra_features_size)\n",
    "\n",
    "iv_surfaces_tensor = TensorDataset(torch.Tensor(x_reshaped ), torch.Tensor(y_reshaped))\n",
    "\n",
    "x = [x[0] for x in iv_surfaces_tensor]\n",
    "y = [x[1] for x in iv_surfaces_tensor]\n",
    "\n",
    "bought_options = []\n",
    "\n",
    "\n",
    "N = 100 ##outcomes to generate\n",
    "\n",
    "\n",
    "##only do ttm of 1\n",
    "for i in range(32, 132): ##start from 32 so i can have enough context\n",
    "    x_hat = []\n",
    "    r_hat = []\n",
    "\n",
    "    \n",
    "    options_t = options.loc[i]\n",
    "    x_c = x[i-31:i]\n",
    "    y_c = y[i-31:i]\n",
    "\n",
    "    x_c = torch.stack(x_c)\n",
    "    y_c = torch.stack(y_c)\n",
    "\n",
    "    for _, selected_row in options_t.iterrows():\n",
    "        T = selected_row[\"Time to Maturity (Months)\"] ##TTM in months\n",
    "        if int(T) != 24:\n",
    "            continue\n",
    "        S = selected_row[\"Asset Price\"] \n",
    "        K = selected_row[\"Strike\"]\n",
    "        market_price = selected_row[\"Call Price\"]\n",
    "        iv = find_iv(market_price, S, K, T / 12, r)\n",
    "        #print(iv)\n",
    "        if iv == np.nan:\n",
    "            continue\n",
    "            \n",
    "        level, diff, moneyness_index, ttm_index = find_closest_moneyness_range_and_ttm(S, K, int(T))\n",
    "\n",
    "        if moneyness_index == 99:\n",
    "            continue\n",
    "            \n",
    "        forecast_iv = predict_iv(x_c, y_c, int(T), N, moneyness_index, ttm_index)\n",
    "\n",
    "        if diff < 0.05: ##close to actual moneyness level compare ivs with ttm and moneyness on forecast - will be underpriced\n",
    "            #print('I AM HERE')\n",
    "            if abs(forecast_iv) < abs(iv): ###if profit is above a threshold here for room \n",
    "                bought_options.append((i, S, K, T, market_price)) \n",
    "\n",
    "    #print(i)\n",
    "\n",
    "total_profit = 0\n",
    "\n",
    "print(f\"{len(bought_options)} options bought\")\n",
    "for option in bought_options:\n",
    "    buy_date, S, K, T, market_price = option\n",
    "    expiration_date = buy_date + int(T) * 30 #months\n",
    "    if expiration_date < 5886:\n",
    "        asset_price_at_expiration = options.loc[expiration_date][\"Asset Price\"].iloc[0]\n",
    "            # If asset_price_at_expiration is a scalar value, calculate profit as before\n",
    "        if asset_price_at_expiration > K:\n",
    "            profit = asset_price_at_expiration - K - market_price\n",
    "        else:\n",
    "            profit = -market_price \n",
    "            total_profit += profit\n",
    "\n",
    "print(f\"{len(bought_options)} options bought\")\n",
    "print(f\"Total profit: {total_profit}\")\n",
    "print(f\"Profit per trade: {total_profit / len(bought_options)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
