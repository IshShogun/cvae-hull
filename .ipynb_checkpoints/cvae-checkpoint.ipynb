{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "470b36e2-1b4a-4d9b-80be-4107567d0e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CVAE_LSTM(nn.Module):\n",
    "    def __init__(self, iv_dim, feature_dim, hidden_dim, latent_dim, num_layers, dropout_rate):\n",
    "        input_dim = iv_dim + feature_dim\n",
    "        super(CVAE_LSTM, self).__init__() ##call the constructor of the pytorch nn module for the nn architecture\n",
    "        self.iv_dim = iv_dim\n",
    "        self.feature_dim = feature_dim\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_rate = dropout_rate #probability a neuron wont activate/be dropped out - prevents overfitting and coadaption btw nn\n",
    "\n",
    "        # Encoder\n",
    "\n",
    "        ##we define an an lstm layer for the encoder consuming the ts data and providing a hidden state\n",
    "        ##the mu and logvar layers provide nns to predict the parameters of the prob distribution for the latent represenation z given context x\n",
    "        ##these consume the hidden state to produce the predictions\n",
    "        self.encoder_lstm = nn.LSTM(iv_dim + 1, hidden_dim, num_layers, batch_first=True, dropout=dropout_rate) ##only encode log returns for future\n",
    "        self.encoder_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.encoder_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "        # Context Encoder\n",
    "        ##the encoder learns the probability distribution then when we have an data to encode we use this, maybe use the \n",
    "        self.context_encoder_lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout_rate) #why only to lstm? - smth to write about\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder_lstm = nn.LSTM(latent_dim + hidden_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.decoder_output = nn.Linear(hidden_dim, input_dim) #output is not input dim\n",
    "\n",
    "    def encode(self, x):\n",
    "        _, (h_n, _) = self.encoder_lstm(x)\n",
    "        h_n = h_n.view(self.num_layers, -1, self.hidden_dim)[-1]\n",
    "        mu = self.encoder_mu(h_n)\n",
    "        logvar = self.encoder_logvar(h_n)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z, context):\n",
    "        decoder_input = torch.cat((z, context), dim=-1)\n",
    "        output, _ = self.decoder_lstm(decoder_input)\n",
    "        output = self.decoder_output(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, x_c, y_c, x_n, r_n):\n",
    "        # Encode historical context\n",
    "        _, (context, _) = self.context_encoder_lstm(torch.cat((x_c, y_c), dim=-1))\n",
    "        context = context.view(self.num_layers, -1, self.hidden_dim)[-1]\n",
    "        \n",
    "        # Encode future values - will have a different dimensionality 25 + 1 as we only predict future log returns\n",
    "        mu, logvar = self.encode(torch.cat((x_n, r_n), dim=-1))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        # Decode future values\n",
    "        x_hat, r_hat = self.decode(z, context).split(self.iv_dim, dim=-1)\n",
    "\n",
    "        return x_hat, r_hat, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3914f2eb-7f10-4896-9685-6926e4e6edec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (3885, 25) (3885, 3)\n",
      "Validation set shape: (1000, 25) (1000, 3)\n",
      "Test set shape: (1000, 25) (1000, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sl/_44jn7jx03b17y35qvlp17sr0000gn/T/ipykernel_99456/4159740756.py:13: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  X = df.drop(['Log Return', 'Skew', 'Slope'], axis=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the DataFrame from the provided CSV file\n",
    "file_path = 'combined_iv_data.csv'\n",
    "df = pd.read_csv(file_path, header=[0,1], index_col=0)\n",
    "\n",
    "#extra features will be these below\n",
    "Y = df[['Log Return', 'Skew', 'Slope']]\n",
    "\n",
    "# X will be all iv surface data - no features\n",
    "X = df.drop(['Log Return', 'Skew', 'Slope'], axis=1)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "Y_scaled = scaler.fit_transform(Y)\n",
    "\n",
    "# Split data into training and temporary set\n",
    "#tarining will have 4000 (saved 2000 for test and validation in temp)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, Y_scaled, test_size=2000, random_state=42)\n",
    "\n",
    "#X_train has all iv surface data to train with\n",
    "#y_train has all the extra features\n",
    "\n",
    "# Split the temporary set into validation and test sets, by splitting temp in half -> 1000 each\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Output the shapes of the splits to confirm the operation\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "771b67ba-a4d2-46ef-950a-a6cea1eb4b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_random_day(n, arr):\n",
    "    \"\"\"\n",
    "    Generates a random number between 1 and n,\n",
    "    and checks if it is not already in the given array.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        # Generate a random number between 1 and n\n",
    "        random_number = random.randint(1, n - 1)\n",
    "        \n",
    "        # Check if the random number is not in the array\n",
    "        if random_number not in arr:\n",
    "            arr.append(random_number)\n",
    "            return random_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3f8961-d55a-40a4-b2eb-1daf21b7ba4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([7, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([7, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([28, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([28, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([14, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([14, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([21, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([21, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([25, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([25, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([16, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([16, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([11, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([11, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([4, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([6, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([6, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([26, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([26, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IV Surface Loss: 1.0273935794830322\n",
      "Log Return Loss: 0.9186657667160034\n",
      "KL Loss: 0.011667430400848389\n",
      "\n",
      "IV Surface Loss: 0.9749563932418823\n",
      "Log Return Loss: 0.7491581439971924\n",
      "KL Loss: 0.010328978300094604\n",
      "\n",
      "IV Surface Loss: 2.118133306503296\n",
      "Log Return Loss: 0.7288910746574402\n",
      "KL Loss: 0.013163387775421143\n",
      "\n",
      "IV Surface Loss: 0.876727819442749\n",
      "Log Return Loss: 0.8127350807189941\n",
      "KL Loss: 0.013361185789108276\n",
      "\n",
      "IV Surface Loss: 1.038958191871643\n",
      "Log Return Loss: 0.8238745331764221\n",
      "KL Loss: 0.015007048845291138\n",
      "\n",
      "IV Surface Loss: 1.2281951904296875\n",
      "Log Return Loss: 1.2625442743301392\n",
      "KL Loss: 0.016469061374664307\n",
      "\n",
      "IV Surface Loss: 1.2127280235290527\n",
      "Log Return Loss: 0.7841317653656006\n",
      "KL Loss: 0.015723377466201782\n",
      "\n",
      "IV Surface Loss: 1.0995434522628784\n",
      "Log Return Loss: 2.412966012954712\n",
      "KL Loss: 0.01393178105354309\n",
      "\n",
      "IV Surface Loss: 0.8995498418807983\n",
      "Log Return Loss: 0.9098942279815674\n",
      "KL Loss: 0.01361304521560669\n",
      "\n",
      "IV Surface Loss: 1.0473361015319824\n",
      "Log Return Loss: 0.8535180687904358\n",
      "KL Loss: 0.016462653875350952\n",
      "\n",
      "IV Surface Loss: 0.9361996650695801\n",
      "Log Return Loss: 1.0378488302230835\n",
      "KL Loss: 0.023055434226989746\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([24, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([24, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([20, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([20, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([12, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([12, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([27, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([27, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([3, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([3, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([19, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([19, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([29, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([29, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([8, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([2, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([18, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([18, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IV Surface Loss: 0.8183916211128235\n",
      "Log Return Loss: 1.567029356956482\n",
      "KL Loss: 0.02040991187095642\n",
      "\n",
      "IV Surface Loss: 0.8264096975326538\n",
      "Log Return Loss: 1.4791979789733887\n",
      "KL Loss: 0.027158737182617188\n",
      "\n",
      "IV Surface Loss: 1.146388292312622\n",
      "Log Return Loss: 1.1815879344940186\n",
      "KL Loss: 0.026656419038772583\n",
      "\n",
      "IV Surface Loss: 0.4098665416240692\n",
      "Log Return Loss: 0.7016210556030273\n",
      "KL Loss: 0.014772117137908936\n",
      "\n",
      "IV Surface Loss: 0.24276329576969147\n",
      "Log Return Loss: 0.5029217004776001\n",
      "KL Loss: 0.011256992816925049\n",
      "\n",
      "IV Surface Loss: 1.3103806972503662\n",
      "Log Return Loss: 1.279817819595337\n",
      "KL Loss: 0.026537925004959106\n",
      "\n",
      "IV Surface Loss: 0.9464860558509827\n",
      "Log Return Loss: 0.9408299326896667\n",
      "KL Loss: 0.02828758955001831\n",
      "\n",
      "IV Surface Loss: 1.09833824634552\n",
      "Log Return Loss: 0.664018452167511\n",
      "KL Loss: 0.030503660440444946\n",
      "\n",
      "IV Surface Loss: 1.2054194211959839\n",
      "Log Return Loss: 0.966587483882904\n",
      "KL Loss: 0.02053019404411316\n",
      "\n",
      "IV Surface Loss: 0.5995274782180786\n",
      "Log Return Loss: 1.1887192726135254\n",
      "KL Loss: 0.05363571643829346\n",
      "\n",
      "IV Surface Loss: 0.6261749267578125\n",
      "Log Return Loss: 2.4296319484710693\n",
      "KL Loss: 0.028352022171020508\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([5, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([5, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([23, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([23, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([13, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([13, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([15, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([15, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([22, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([22, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([10, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([10, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([17, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([17, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([31, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([31, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([30, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([30, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([9, 25])) that is different to the input size (torch.Size([1, 25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([9, 1])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IV Surface Loss: 0.857948362827301\n",
      "Log Return Loss: 1.1669273376464844\n",
      "KL Loss: 0.03228771686553955\n",
      "\n",
      "IV Surface Loss: 0.5402281880378723\n",
      "Log Return Loss: 1.1719120740890503\n",
      "KL Loss: 0.03198656439781189\n",
      "\n",
      "IV Surface Loss: 0.7334268689155579\n",
      "Log Return Loss: 0.7508378624916077\n",
      "KL Loss: 0.0427497923374176\n",
      "\n",
      "IV Surface Loss: 0.6305726170539856\n",
      "Log Return Loss: 0.6677422523498535\n",
      "KL Loss: 0.0354803204536438\n",
      "\n",
      "IV Surface Loss: 0.9311909675598145\n",
      "Log Return Loss: 1.767519235610962\n",
      "KL Loss: 0.03237342834472656\n",
      "\n",
      "IV Surface Loss: 0.6642863154411316\n",
      "Log Return Loss: 0.3541199564933777\n",
      "KL Loss: 0.03373616933822632\n",
      "\n",
      "IV Surface Loss: 0.7717457413673401\n",
      "Log Return Loss: 0.7232272028923035\n",
      "KL Loss: 0.043373048305511475\n",
      "\n",
      "IV Surface Loss: 1.4280444383621216\n",
      "Log Return Loss: 1.362480878829956\n",
      "KL Loss: 0.05516138672828674\n",
      "\n",
      "IV Surface Loss: 1.2730417251586914\n",
      "Log Return Loss: 0.8026449680328369\n",
      "KL Loss: 0.045615196228027344\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Define hyperparameters\n",
    "latent_dim = 5\n",
    "context_dim = 5\n",
    "hidden_dim = 100\n",
    "num_layers = 2\n",
    "dropout_rate = 0.2\n",
    "kl_weight = 1e-5\n",
    "num_epochs = 500\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "\n",
    "train_data = TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train))\n",
    "val_data = TensorDataset(torch.Tensor(X_val), torch.Tensor(y_val))\n",
    "test_data = TensorDataset(torch.Tensor(X_test), torch.Tensor(y_test))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#input is historical iv and extra features\n",
    "model = CVAE_LSTM(iv_dim=(X_train.shape[-1]), feature_dim=(y_train.shape[-1]), hidden_dim=hidden_dim, latent_dim=latent_dim,\n",
    "                  num_layers=num_layers, dropout_rate=dropout_rate)\n",
    "\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate) #step in right direction\n",
    "\n",
    "arr = []\n",
    "# Training loop\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_surface_loss = 0.0\n",
    "    train_return_loss = 0.0\n",
    "    train_kl_loss = 0.0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        #this gets us all iv surface and extra feature data for the batch\n",
    "        X_batch, Y_batch = batch\n",
    "\n",
    "        n = Y_batch.shape[0] #days to sample from\n",
    "        #generate a random t not already generated\n",
    "        t = generate_random_day(n, arr)\n",
    "\n",
    "        #up to t-1 is context from t -> end is future\n",
    "        x_c, x_n = X_batch[:t], X_batch[t:]\n",
    "        y_c, r_n = Y_batch[:t], Y_batch[t:] #need only the asset returns here\n",
    "\n",
    "        #now from here reassing r_n to only have the log return feature - log returns at 0th index\n",
    "        r_n = r_n[:, 0].unsqueeze(1)\n",
    "    \n",
    "        x_hat, r_hat, mu, logvar = model(x_c, y_c, x_n, r_n)\n",
    "\n",
    "\n",
    "        surface_loss = criterion(x_hat, x_n)\n",
    "        return_loss = criterion(r_hat, r_n)\n",
    "        kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "        loss = surface_loss + return_loss + kl_weight * kl_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_surface_loss += surface_loss.item()\n",
    "        train_return_loss += return_loss.item()\n",
    "        train_kl_loss += kl_loss.item()\n",
    "        print(f\"IV Surface Loss: {surface_loss.item()}\")\n",
    "        print(f\"Log Return Loss: {return_loss.item()}\")\n",
    "        print(f\"KL Loss: {kl_loss.item()}\\n\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_surface_loss = 0.0\n",
    "    val_return_loss = 0.0\n",
    "    val_kl_loss = 0.0\n",
    "    arr = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            #this gets us all iv surface and extra feature data for the batch\n",
    "            X_batch, Y_batch = batch\n",
    "    \n",
    "            n = Y_batch.shape[0] #days to sample from\n",
    "            #generate a random t not already generated\n",
    "            t = generate_random_day(n, arr)\n",
    "    \n",
    "            #up to t-1 is context from t -> end is future\n",
    "            x_c, x_n = X_batch[:t], X_batch[t:]\n",
    "            y_c, r_n = Y_batch[:t], Y_batch[t:] #need only the asset returns here\n",
    "    \n",
    "            #now from here reassing r_n to only have the log return feature - log returns at 0th index\n",
    "            r_n = r_n[:, 0].unsqueeze(1)\n",
    "            \n",
    "            x_hat, r_hat, mu, logvar = model(x_c, y_c, x_n, r_n)\n",
    "\n",
    "            surface_loss = criterion(x_hat, x_n)\n",
    "            return_loss = criterion(r_hat, r_n)\n",
    "            kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "            val_surface_loss += surface_loss.item()\n",
    "            val_return_loss += return_loss.item()\n",
    "            val_kl_loss += kl_loss.item()\n",
    "            print(\"ahahha\")\n",
    "\n",
    "    # Print epoch statistics\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "          f\"Train Surface Loss: {train_surface_loss / len(train_loader):.4f}, \"\n",
    "          f\"Train Return Loss: {train_return_loss / len(train_loader):.4f}, \"\n",
    "          f\"Train KL Loss: {train_kl_loss / len(train_loader):.4f}, \"\n",
    "          f\"Val Surface Loss: {val_surface_loss / len(val_loader):.4f}, \"\n",
    "          f\"Val Return Loss: {val_return_loss / len(val_loader):.4f}, \"\n",
    "          f\"Val KL Loss: {val_kl_loss / len(val_loader):.4f}\")\n",
    "\n",
    "    # Save the best model based on validation loss\n",
    "    val_loss = val_surface_loss + val_return_loss + kl_weight * val_kl_loss\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "# Evaluation on the test set\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()\n",
    "test_surface_loss = 0.0\n",
    "test_return_loss = 0.0\n",
    "test_kl_loss = 0.0\n",
    "arr = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        #this gets us all iv surface and extra feature data for the batch\n",
    "        X_batch, Y_batch = batch\n",
    "\n",
    "        n = Y_batch.shape[0] #days to sample from\n",
    "        #generate a random t not already generated\n",
    "        t = generate_random_day(n, arr)\n",
    "\n",
    "        #up to t-1 is context from t -> end is future\n",
    "        x_c, x_n = X_batch[:t], X_batch[t:]\n",
    "        y_c, r_n = Y_batch[:t], Y_batch[t:] #need only the asset returns here\n",
    "\n",
    "        #now from here reassing r_n to only have the log return feature - log returns at 0th index\n",
    "        r_n = r_n[:, 0].unsqueeze(1)\n",
    "        x_hat, r_hat, mu, logvar = model(x_c, y_c, x_n, r_n)\n",
    "\n",
    "        surface_loss = criterion(x_hat, x_n)\n",
    "        return_loss = criterion(r_hat, r_n)\n",
    "        kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "        test_surface_loss += surface_loss.item()\n",
    "        test_return_loss += return_loss.item()\n",
    "        test_kl_loss += kl_loss.item()\n",
    "\n",
    "print(f\"Test Surface Loss: {test_surface_loss / len(test_loader):.4f}, \"\n",
    "      f\"Test Return Loss: {test_return_loss / len(test_loader):.4f}, \"\n",
    "      f\"Test KL Loss: {test_kl_loss / len(test_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaec439-b0aa-44d0-a7f9-5dae1b77aadd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
